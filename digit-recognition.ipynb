{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Prediction with Convolutional Neural Network\n",
    "\n",
    "- MNIST dataset: is a dataset of 60,000 28x28 grayscale images of the 10 digits, along with a test set of 10,000 images. More info can be found at the [MNIST homepage](http://yann.lecun.com/exdb/mnist/).\n",
    "- Goal: build a simple artificial neural network to predict the digit in the images.\n",
    "- Reference: [Oddly Satisfying Deep Learning](https://pythonandml.github.io/dlbook/content/convolutional_neural_networks/cnn_over_mlp.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for linear algebra\n",
    "import numpy as np\n",
    "\n",
    "# for plotting data, loss, accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# loading mnist dataset from keras\n",
    "from keras import datasets\n",
    "\n",
    "# show progress bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# for type hinting\n",
    "from typing import Optional, Union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Utils Functions\n",
    "\n",
    "1. **plot_data**: plot the random 8 images from the dataset.\n",
    "2. **Base Layer**: Base class for all the layers.\n",
    "3. **Activation Functions**: Linear, reLU, Sigmoid, Tanh, Softmax.\n",
    "3. **Weight Initialization**: Zeros, Ones, Random, Random Uniform.\n",
    "4. **Optimization Functions**: Gradient Descent, Stochastic Gradient Descent, RMSprop, Adam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1. Plotting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(\n",
    "    X: np.ndarray, y: np.ndarray, y_proba: Optional[np.ndarray] = None\n",
    ") -> None:\n",
    "    nrows, ncols = 2, 4\n",
    "    _, axes = plt.subplots(nrows, ncols, figsize=(8, 4))\n",
    "\n",
    "    len_x = X.shape[0]\n",
    "    for idx in range(nrows * ncols):\n",
    "        ax = axes[idx // ncols, idx % ncols]\n",
    "\n",
    "        img_idx = np.random.randint(0, len_x)\n",
    "\n",
    "        ax.imshow(X[img_idx], cmap=\"gray\")\n",
    "        ax.set(xticks=[], yticks=[])\n",
    "\n",
    "        true_label = f\"True: {y[img_idx]}\"\n",
    "        color = \"black\"\n",
    "\n",
    "        if y_proba is not None:\n",
    "            pred_label = f\"Pred: {y_proba[img_idx]}\"\n",
    "            color = \"green\" if y[img_idx] == y_proba[img_idx] else \"red\"\n",
    "\n",
    "        img_title = true_label if y_proba is None else f\"{true_label}\\n{pred_label}\"\n",
    "        ax.set_xlabel(img_title, color=color)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2. Activation Functions class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation:\n",
    "\n",
    "    def __init__(self, activation_type=None):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "\n",
    "        activation_type: type of activation\n",
    "        available options are 'sigmoid', 'linear', 'tanh', 'softmax', 'prelu' and 'relu'\n",
    "        \"\"\"\n",
    "        if activation_type is None:\n",
    "            self.activation_type = \"linear\"\n",
    "        else:\n",
    "            self.activation_type = activation_type\n",
    "\n",
    "    def linear(self, x):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "\n",
    "        x: input matrix of shape (m, d)\n",
    "        where 'm' is the number of samples (in case of batch gradient descent of size m)\n",
    "        and 'd' is the number of features\n",
    "        \"\"\"\n",
    "        return x\n",
    "\n",
    "    def d_linear(self, x):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "\n",
    "        x: input matrix of shape (m, d)\n",
    "        where 'm' is the number of samples (in case of batch gradient descent of size m)\n",
    "        and 'd' is the number of features\n",
    "        \"\"\"\n",
    "        return np.ones(x.shape)\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "\n",
    "        x: input matrix of shape (m, d)\n",
    "        where 'm' is the number of samples (in case of batch gradient descent of size m)\n",
    "        and 'd' is the number of features\n",
    "        \"\"\"\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def d_sigmoid(self, x):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "\n",
    "        x: input matrix of shape (m, d)\n",
    "        where 'm' is the number of samples (in case of batch gradient descent of size m)\n",
    "        and 'd' is the number of features\n",
    "        \"\"\"\n",
    "        return self.sigmoid(x) * (1 - self.sigmoid(x))\n",
    "\n",
    "    def tanh(self, x):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "\n",
    "        x: input matrix of shape (m, d)\n",
    "        where 'm' is the number of samples (in case of batch gradient descent of size m)\n",
    "        and 'd' is the number of features\n",
    "        \"\"\"\n",
    "        return (np.exp(x) - np.exp(-x)) / (np.exp(x) + np.exp(-x))\n",
    "\n",
    "    def d_tanh(self, x):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "\n",
    "        x: input matrix of shape (m, d)\n",
    "        where 'm' is the number of samples (in case of batch gradient descent of size m)\n",
    "        and 'd' is the number of features\n",
    "        \"\"\"\n",
    "        return 1 - (self.tanh(x)) ** 2\n",
    "\n",
    "    def ReLU(self, x):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "\n",
    "        x: input matrix of shape (m, d)\n",
    "        where 'm' is the number of samples (in case of batch gradient descent of size m)\n",
    "        and 'd' is the number of features\n",
    "        \"\"\"\n",
    "        return x * (x > 0)\n",
    "\n",
    "    def d_ReLU(self, x):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "\n",
    "        x: input matrix of shape (m, d)\n",
    "        where 'm' is the number of samples (in case of batch gradient descent of size m)\n",
    "        and 'd' is the number of features\n",
    "        \"\"\"\n",
    "        return (x > 0) * np.ones(x.shape)\n",
    "\n",
    "    def PReLU(self, x, alpha=0.2):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        alpha: slope parameter (ð›¼)\n",
    "\n",
    "        x: input matrix of shape (m, d)\n",
    "        where 'm' is the number of samples (or rows)\n",
    "        and 'd' is the number of features (or columns)\n",
    "        \"\"\"\n",
    "        return np.where(x > 0, x, alpha * x)\n",
    "\n",
    "    def d_PReLU(self, x, alpha=0.2):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        alpha: slope parameter (ð›¼)\n",
    "\n",
    "        x: input matrix of shape (m, d)\n",
    "        where 'm' is the number of samples (or rows)\n",
    "        and 'd' is the number of features (or columns)\n",
    "        \"\"\"\n",
    "        return np.where(x > 0, 1, alpha)\n",
    "\n",
    "    def softmax(self, x):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "\n",
    "        x: input matrix of shape (m, d)\n",
    "        where 'm' is the number of samples (in case of batch gradient descent of size m)\n",
    "        and 'd' is the number of features\n",
    "        \"\"\"\n",
    "        z = x - np.max(x, axis=-1, keepdims=True)\n",
    "        numerator = np.exp(z)\n",
    "        denominator = np.sum(numerator, axis=-1, keepdims=True)\n",
    "        softmax = numerator / denominator\n",
    "        return softmax\n",
    "\n",
    "    def d_softmax(self, x):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "\n",
    "        x: input matrix of shape (m, d)\n",
    "        where 'm' is the number of samples (in case of batch gradient descent of size m)\n",
    "        and 'd' is the number of features\n",
    "        \"\"\"\n",
    "        if len(x.shape) == 1:\n",
    "            x = np.array(x).reshape(1, -1)\n",
    "        else:\n",
    "            x = np.array(x)\n",
    "        m, d = x.shape\n",
    "        a = self.softmax(x)\n",
    "        tensor1 = np.einsum(\"ij,ik->ijk\", a, a)\n",
    "        tensor2 = np.einsum(\"ij,jk->ijk\", a, np.eye(d, d))\n",
    "        return tensor2 - tensor1\n",
    "\n",
    "    def get_activation(self, x):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "\n",
    "        x: input matrix of shape (m, d)\n",
    "        where 'm' is the number of samples (in case of batch gradient descent of size m)\n",
    "        and 'd' is the number of features\n",
    "        \"\"\"\n",
    "        if self.activation_type == \"sigmoid\":\n",
    "            return self.sigmoid(x)\n",
    "        elif self.activation_type == \"tanh\":\n",
    "            return self.tanh(x)\n",
    "        elif self.activation_type == \"relu\":\n",
    "            return self.ReLU(x)\n",
    "        elif self.activation_type == \"linear\":\n",
    "            return self.linear(x)\n",
    "        elif self.activation_type == \"prelu\":\n",
    "            return self.PReLU(x)\n",
    "        elif self.activation_type == \"softmax\":\n",
    "            return self.softmax(x)\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Valid Activations are only 'sigmoid', 'linear', 'tanh' 'softmax', 'prelu' and 'relu'\"\n",
    "            )\n",
    "\n",
    "    def get_d_activation(self, x):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "\n",
    "        x: input matrix of shape (m, d)\n",
    "        where 'm' is the number of samples (in case of batch gradient descent of size m)\n",
    "        and 'd' is the number of features\n",
    "        \"\"\"\n",
    "        if self.activation_type == \"sigmoid\":\n",
    "            return self.d_sigmoid(x)\n",
    "        elif self.activation_type == \"tanh\":\n",
    "            return self.d_tanh(x)\n",
    "        elif self.activation_type == \"relu\":\n",
    "            return self.d_ReLU(x)\n",
    "        elif self.activation_type == \"linear\":\n",
    "            return self.d_linear(x)\n",
    "        elif self.activation_type == \"prelu\":\n",
    "            return self.d_PReLU(x)\n",
    "        elif self.activation_type == \"softmax\":\n",
    "            return self.d_softmax(x)\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Valid Activations are only 'sigmoid', 'linear', 'tanh', 'softmax', 'prelu' and 'relu'\"\n",
    "            )\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.X = X\n",
    "        z = self.get_activation(X)\n",
    "        return z\n",
    "\n",
    "    def backpropagation(self, dz):\n",
    "        f_prime = self.get_d_activation(self.X)\n",
    "        if self.activation_type == \"softmax\":\n",
    "            # because derivative of softmax is a tensor\n",
    "            dx = np.einsum(\"ijk,ik->ij\", f_prime, dz)\n",
    "        else:\n",
    "            dx = dz * f_prime\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.3. Weight Initialization class\n",
    "\n",
    "- Zeros initialization: $w = np.zeros(shape)$\n",
    "- Ones initialization: $w = np.ones(shape)$\n",
    "- Random initialization: $w = np.random.randn(shape)$\n",
    "- Random uniform initialization: $w = np.random.uniform(size=shape)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Weights_initializer:\n",
    "\n",
    "    def __init__(self, shape, initializer_type=None, seed=None):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        shape: Shape of the weight matrix\n",
    "\n",
    "        initializer_type: type of weight initializer\n",
    "        available options are 'zeros', 'ones', 'random_normal', 'random_uniform',\n",
    "        'he_normal', 'xavier_normal' and 'glorot_normal'\n",
    "        \"\"\"\n",
    "        self.shape = shape\n",
    "        if initializer_type is None:\n",
    "            self.initializer_type = \"he_normal\"\n",
    "        else:\n",
    "            self.initializer_type = initializer_type\n",
    "        self.seed = seed\n",
    "\n",
    "    def zeros_initializer(self):\n",
    "        if self.seed is not None:\n",
    "            np.random.seed(self.seed)\n",
    "        return np.zeros(self.shape)\n",
    "\n",
    "    def ones_initializer(self):\n",
    "        if self.seed is not None:\n",
    "            np.random.seed(self.seed)\n",
    "        return np.ones(self.shape)\n",
    "\n",
    "    def random_normal_initializer(self):\n",
    "        if self.seed is not None:\n",
    "            np.random.seed(self.seed)\n",
    "        return np.random.normal(size=self.shape)\n",
    "\n",
    "    def random_uniform_initializer(self):\n",
    "        if self.seed is not None:\n",
    "            np.random.seed(self.seed)\n",
    "        return np.random.uniform(size=self.shape)\n",
    "\n",
    "    def he_initializer(self):\n",
    "        if self.seed is not None:\n",
    "            np.random.seed(self.seed)\n",
    "        try:\n",
    "            F, Kc, Kh, Kw = self.shape\n",
    "        except:\n",
    "            Kh, Kw = self.shape\n",
    "        return np.random.randn(*self.shape) * np.sqrt(2 / Kh)\n",
    "\n",
    "    def xavier_initializer(self):\n",
    "        \"\"\"\n",
    "        shape: Shape of the Kernel matrix.\n",
    "        \"\"\"\n",
    "        if self.seed is not None:\n",
    "            np.random.seed(self.seed)\n",
    "        try:\n",
    "            F, Kc, Kh, Kw = self.shape\n",
    "        except:\n",
    "            Kh, Kw = self.shape\n",
    "        return np.random.randn(*self.shape) * np.sqrt(1 / Kh)\n",
    "\n",
    "    def glorot_initializer(self):\n",
    "        \"\"\"\n",
    "        shape: Shape of the weight matrix.\n",
    "        \"\"\"\n",
    "        if self.seed is not None:\n",
    "            np.random.seed(self.seed)\n",
    "        try:\n",
    "            F, Kc, Kh, Kw = self.shape\n",
    "        except:\n",
    "            Kh, Kw = self.shape\n",
    "        return np.random.randn(*self.shape) * np.sqrt(2 / (Kh + Kw))\n",
    "\n",
    "    def get_initializer(self):\n",
    "        if self.initializer_type == \"zeros\":\n",
    "            return self.zeros_initializer()\n",
    "        elif self.initializer_type == \"ones\":\n",
    "            return self.ones_initializer()\n",
    "        elif self.initializer_type == \"random_normal\":\n",
    "            return self.random_normal_initializer()\n",
    "        elif self.initializer_type == \"random_uniform\":\n",
    "            return self.random_uniform_initializer()\n",
    "        elif self.initializer_type == \"he_normal\":\n",
    "            return self.he_initializer()\n",
    "        elif self.initializer_type == \"xavier_normal\":\n",
    "            return self.xavier_initializer()\n",
    "        elif self.initializer_type == \"glorot_normal\":\n",
    "            return self.glorot_initializer()\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Valid initializer options are 'zeros', 'ones', 'random_normal', 'random_uniform', 'he_normal', 'xavier_normal', and 'glorot_normal'\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4.  Optimizers class\n",
    "\n",
    "- Gradient Descent Optimizer: $w = w - \\alpha \\nabla_w L(w)$\n",
    "- Stochastic Gradient Descent Optimizer: $w = w - \\alpha \\nabla_w L(w)$\n",
    "- RMSprop Optimizer: $v = \\beta v + (1 - \\beta) \\nabla_w L(w) \\odot \\nabla_w L(w)$ and $w = w - \\alpha \\frac{\\nabla_w L(w)}{\\sqrt{v + \\epsilon}}$\n",
    "- Adam Optimizer: $m = \\beta_1 m + (1 - \\beta_1) \\nabla_w L(w)$, $v = \\beta_2 v + (1 - \\beta_2) \\nabla_w L(w) \\odot \\nabla_w L(w)$, $m_{\\text{corrected}} = \\frac{m}{1 - \\beta_1^t}$, $v_{\\text{corrected}} = \\frac{v}{1 - \\beta_2^t}$, and $w = w - \\alpha \\frac{m_{\\text{corrected}}}{\\sqrt{v_{\\text{corrected}} + \\epsilon}}$\n",
    "\n",
    "> Note: Actually, i only use the Gradient Descent Optimizer in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        optimizer_type=None,\n",
    "        shape_W=None,\n",
    "        shape_b=None,\n",
    "        momentum1=0.9,\n",
    "        momentum2=0.999,\n",
    "        epsilon=1e-8,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "\n",
    "        momentum1: float hyperparameter >= 0 that accelerates gradient descent in the relevant\n",
    "                   direction and dampens oscillations. Defaults to 0, i.e., vanilla gradient descent.\n",
    "                   Also used in RMSProp\n",
    "        momentum2: used in Adam only\n",
    "        optimizer_type: type of optimizer\n",
    "                        available options are 'gd', 'sgd' (This also includes momentum), 'adam', and 'rmsprop'\n",
    "        shape_W: Shape of the weight matrix W/ Kernel K\n",
    "        shape_b: Shape of the bias matrix b\n",
    "        epsilon: parameter used in RMSProp and Adam to avoid division by zero error\n",
    "        \"\"\"\n",
    "\n",
    "        if optimizer_type is None:\n",
    "            self.optimizer_type = \"adam\"\n",
    "        else:\n",
    "            self.optimizer_type = optimizer_type\n",
    "\n",
    "        self.momentum1 = momentum1\n",
    "        self.momentum2 = momentum2\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "        self.vdW = np.zeros(shape_W)\n",
    "        self.vdb = np.zeros(shape_b)\n",
    "\n",
    "        self.SdW = np.zeros(shape_W)\n",
    "        self.Sdb = np.zeros(shape_b)\n",
    "\n",
    "    def GD(self, dW, db, k):\n",
    "        \"\"\"\n",
    "        dW: gradient of Weight W for iteration k\n",
    "        db: gradient of bias b for iteration k\n",
    "        k: iteration number\n",
    "        \"\"\"\n",
    "        return dW, db\n",
    "\n",
    "    def SGD(self, dW, db, k):\n",
    "        \"\"\"\n",
    "        dW: gradient of Weight W for iteration k\n",
    "        db: gradient of bias b for iteration k\n",
    "        k: iteration number\n",
    "        \"\"\"\n",
    "        self.vdW = self.momentum1 * self.vdW + (1 - self.momentum1) * dW\n",
    "        self.vdb = self.momentum1 * self.vdb + (1 - self.momentum1) * db\n",
    "\n",
    "        return self.vdW, self.vdb\n",
    "\n",
    "    def RMSProp(self, dW, db, k):\n",
    "        \"\"\"\n",
    "        dW: gradient of Weight W for iteration k\n",
    "        db: gradient of bias b for iteration k\n",
    "        k: iteration number\n",
    "        \"\"\"\n",
    "        self.SdW = self.momentum2 * self.SdW + (1 - self.momentum2) * (dW**2)\n",
    "        self.Sdb = self.momentum2 * self.Sdb + (1 - self.momentum2) * (db**2)\n",
    "\n",
    "        den_W = np.sqrt(self.SdW) + self.epsilon\n",
    "        den_b = np.sqrt(self.Sdb) + self.epsilon\n",
    "\n",
    "        return dW / den_W, db / den_b\n",
    "\n",
    "    def Adam(self, dW, db, k):\n",
    "        \"\"\"\n",
    "        dW: gradient of Weight W for iteration k\n",
    "        db: gradient of bias b for iteration k\n",
    "        k: iteration number\n",
    "        \"\"\"\n",
    "        # momentum\n",
    "        self.vdW = self.momentum1 * self.vdW + (1 - self.momentum1) * dW\n",
    "        self.vdb = self.momentum1 * self.vdb + (1 - self.momentum1) * db\n",
    "\n",
    "        # rmsprop\n",
    "        self.SdW = self.momentum2 * self.SdW + (1 - self.momentum2) * (dW**2)\n",
    "        self.Sdb = self.momentum2 * self.Sdb + (1 - self.momentum2) * (db**2)\n",
    "\n",
    "        # correction\n",
    "        if k > 1:\n",
    "            vdW_h = self.vdW / (1 - (self.momentum1**k))\n",
    "            vdb_h = self.vdb / (1 - (self.momentum1**k))\n",
    "            SdW_h = self.SdW / (1 - (self.momentum2**k))\n",
    "            Sdb_h = self.Sdb / (1 - (self.momentum2**k))\n",
    "        else:\n",
    "            vdW_h = self.vdW\n",
    "            vdb_h = self.vdb\n",
    "            SdW_h = self.SdW\n",
    "            Sdb_h = self.Sdb\n",
    "\n",
    "        den_W = np.sqrt(SdW_h) + self.epsilon\n",
    "        den_b = np.sqrt(Sdb_h) + self.epsilon\n",
    "\n",
    "        return vdW_h / den_W, vdb_h / den_b\n",
    "\n",
    "    def get_optimization(self, dW, db, k):\n",
    "        if self.optimizer_type == \"gd\":\n",
    "            return self.GD(dW, db, k)\n",
    "        if self.optimizer_type == \"sgd\":\n",
    "            return self.SGD(dW, db, k)\n",
    "        if self.optimizer_type == \"rmsprop\":\n",
    "            return self.RMSProp(dW, db, k)\n",
    "        if self.optimizer_type == \"adam\":\n",
    "            return self.Adam(dW, db, k)\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Valid optimizer options are only 'gd', 'sgd', 'rmsprop', and 'adam'.\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.5. Cost Functions class\n",
    "\n",
    "- Mean Squared Error Loss: $L(y, \\hat{y}) = \\frac{1}{2} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$\n",
    "- Derivative of Mean Squared Error Loss: $\\frac{\\partial L(y, \\hat{y})}{\\partial \\hat{y}} = \\hat{y} - y$\n",
    "- Binary Cross Entropy Loss: $L(y, \\hat{y}) = - \\sum_{i=1}^{n} y_i \\log(\\hat{y}_i) + (1 - y_i) \\log(1 - \\hat{y}_i)$\n",
    "- Derivative of Binary Cross Entropy Loss: $\\frac{\\partial L(y, \\hat{y})}{\\partial \\hat{y}} = - \\frac{y}{\\hat{y}} + \\frac{1 - y}{1 - \\hat{y}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cost:\n",
    "\n",
    "    def __init__(self, cost_type=\"mse\"):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "\n",
    "        cost_type: type of cost function\n",
    "        available options are 'mse', and 'cross-entropy'\n",
    "        \"\"\"\n",
    "        self.cost_type = cost_type\n",
    "\n",
    "    def mse(self, a, y):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "\n",
    "        a: Predicted output array of shape (m, d)\n",
    "        y: Actual output array of shape (m, d)\n",
    "        \"\"\"\n",
    "        return (1 / 2) * np.sum((np.linalg.norm(a - y, axis=1)) ** 2)\n",
    "\n",
    "    def d_mse(self, a, y):\n",
    "        \"\"\"\n",
    "        represents dJ/da\n",
    "\n",
    "        Parameters\n",
    "\n",
    "        a: Predicted output array of shape (m, d)\n",
    "        y: Actual output array of shape (m, d)\n",
    "        \"\"\"\n",
    "        return a - y\n",
    "\n",
    "    def cross_entropy(self, a, y, epsilon=1e-12):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "\n",
    "        a: Predicted output array of shape (m, d)\n",
    "        y: Actual output array of shape (m, d)\n",
    "        \"\"\"\n",
    "        a = np.clip(a, epsilon, 1.0 - epsilon)\n",
    "        return -np.sum(y * np.log(a))\n",
    "\n",
    "    def d_cross_entropy(self, a, y, epsilon=1e-12):\n",
    "        \"\"\"\n",
    "        represents dJ/da\n",
    "\n",
    "        Parameters\n",
    "\n",
    "        a: Predicted output array of shape (m, d)\n",
    "        y: Actual output array of shape (m, d)\n",
    "        \"\"\"\n",
    "        a = np.clip(a, epsilon, 1.0 - epsilon)\n",
    "        return -y / a\n",
    "\n",
    "    def get_cost(self, a, y):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "\n",
    "        a: Predicted output array of shape (m, d)\n",
    "        y: Actual output array of shape (m, d)\n",
    "        \"\"\"\n",
    "        if self.cost_type == \"mse\":\n",
    "            return self.mse(a, y)\n",
    "        elif self.cost_type == \"cross-entropy\":\n",
    "            return self.cross_entropy(a, y)\n",
    "        else:\n",
    "            raise ValueError(\"Valid cost functions are only 'mse', and 'cross-entropy'\")\n",
    "\n",
    "    def get_d_cost(self, a, y):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "\n",
    "        a: Predicted output array of shape (m, d)\n",
    "        y: Actual output array of shape (m, d)\n",
    "        \"\"\"\n",
    "        if self.cost_type == \"mse\":\n",
    "            return self.d_mse(a, y)\n",
    "        elif self.cost_type == \"cross-entropy\":\n",
    "            return self.d_cross_entropy(a, y)\n",
    "        else:\n",
    "            raise ValueError(\"Valid cost functions are only 'mse', and 'cross-entropy'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.6. Batch Normalization Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNormalization:\n",
    "\n",
    "    def __init__(self, momentum=0.9, epsilon=1e-6):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "\n",
    "        momentum: Momentum for the moving average\n",
    "        epsilon: ðœ–, Small float added to variance to avoid dividing by zero\n",
    "        \"\"\"\n",
    "        self.epsilon = epsilon\n",
    "        self.momentum = momentum\n",
    "\n",
    "    def initialize_parameters(self, d):\n",
    "        \"\"\"\n",
    "        d: Shape of input to BN layer\n",
    "        \"\"\"\n",
    "        self.gamma = np.ones((d))\n",
    "        self.beta = np.zeros((d))\n",
    "        self.running_mean = np.zeros((d))\n",
    "        self.running_var = np.zeros((d))\n",
    "\n",
    "    def forward(self, z, mode=\"train\"):\n",
    "        \"\"\"\n",
    "        z: Input to BN layer\n",
    "        mode: forward pass used for train or test\n",
    "        \"\"\"\n",
    "        if mode == \"train\":\n",
    "            self.m, self.d = z.shape\n",
    "            self.mu = np.mean(z, axis=0)  # ðœ‡\n",
    "            self.var = np.var(z, axis=0)  # ðœŽ^2\n",
    "            self.zmu = z - self.mu  # z - ðœ‡\n",
    "            self.ivar = 1 / np.sqrt(self.var + self.epsilon)  # ðœŽð‘–ð‘›ð‘£\n",
    "            self.zhat = self.zmu * self.ivar\n",
    "            q = self.gamma * self.zhat + self.beta  # ql\n",
    "            self.running_mean = (\n",
    "                self.momentum * self.running_mean + (1 - self.momentum) * self.mu\n",
    "            )\n",
    "            self.running_var = (\n",
    "                self.momentum * self.running_var + (1 - self.momentum) * self.var\n",
    "            )\n",
    "        elif mode == \"test\":\n",
    "            q = (z - self.running_mean) / np.sqrt(self.running_var + self.epsilon)\n",
    "            q = self.gamma * q + self.beta\n",
    "        else:\n",
    "            raise ValueError('Invalid forward batchnorm mode \"%s\"' % mode)\n",
    "        return q\n",
    "\n",
    "    def backpropagation(self, dq):\n",
    "        self.dgamma = np.sum(dq * self.zhat, axis=0)\n",
    "        self.dbeta = np.sum(dq, axis=0)\n",
    "        dzhat = dq * self.gamma\n",
    "        dvar = np.sum(dzhat * self.zmu * (-0.5) * (self.ivar**3), axis=0)\n",
    "        dmu = np.sum(dzhat * (-self.ivar), axis=0)\n",
    "        dz = dzhat * self.ivar + dvar * (2 / self.m) * self.zmu + (1 / self.m) * dmu\n",
    "        return dz\n",
    "\n",
    "    def update(self, lr, m, k):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "\n",
    "        lr: learning rate\n",
    "        m: batch_size (sumber of samples in batch)\n",
    "        k: iteration_number\n",
    "        \"\"\"\n",
    "        self.gamma -= self.dgamma * (lr / m)\n",
    "        self.beta -= self.dbeta * (lr / m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.7. Learning Rate Decay class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearningRateDecay:\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def constant(self, t, lr_0):\n",
    "        \"\"\"\n",
    "        t: iteration\n",
    "        lr_0: initial learning rate\n",
    "        \"\"\"\n",
    "        return lr_0\n",
    "\n",
    "    def time_decay(self, t, lr_0, k):\n",
    "        \"\"\"\n",
    "        lr_0: initial learning rate\n",
    "        k: Decay rate\n",
    "        t: iteration number\n",
    "        \"\"\"\n",
    "        lr = lr_0 / (1 + (k * t))\n",
    "        return lr\n",
    "\n",
    "    def step_decay(self, t, lr_0, F, D):\n",
    "        \"\"\"\n",
    "        lr_0: initial learning rate\n",
    "        F: factor value controlling the rate in which the learning date drops\n",
    "        D: â€œDrop everyâ€ iteration\n",
    "        t: current iteration\n",
    "        \"\"\"\n",
    "        mult = F ** np.floor((1 + t) / D)\n",
    "        lr = lr_0 * mult\n",
    "        return lr\n",
    "\n",
    "    def exponential_decay(self, t, lr_0, k):\n",
    "        \"\"\"\n",
    "        lr_0: initial learning rate\n",
    "        k: Exponential Decay rate\n",
    "        t: iteration number\n",
    "        \"\"\"\n",
    "        lr = lr_0 * np.exp(-k * t)\n",
    "        return lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.8. Library class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Utility:\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def label_encoding(self, Y):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        Y: (m,d) shape matrix with categorical data\n",
    "        Return\n",
    "        result: label encoded data of ð‘Œ\n",
    "        idx_list: list of the dictionaries containing the unique values\n",
    "                  of the columns and their mapping to the integer.\n",
    "        \"\"\"\n",
    "        idx_list = []\n",
    "        result = []\n",
    "        for col in range(Y.shape[1]):\n",
    "            indexes = {val: idx for idx, val in enumerate(np.unique(Y[:, col]))}\n",
    "            result.append([indexes[s] for s in Y[:, col]])\n",
    "            idx_list.append(indexes)\n",
    "        return np.array(result).T, idx_list\n",
    "\n",
    "    def onehot(self, X):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        X: 1D array of labels of length \"m\"\n",
    "        Return\n",
    "        X_onehot: (m,d) one hot encoded matrix (one-hot of X)\n",
    "                  (where d is the number of unique values in X)\n",
    "        indexes: dictionary containing the unique values of X and their mapping to the integer column\n",
    "        \"\"\"\n",
    "        indexes = {val: idx for idx, val in enumerate(np.unique(X))}\n",
    "        y = np.array([indexes[s] for s in X])\n",
    "        X_onehot = np.zeros((y.size, len(indexes)))\n",
    "        X_onehot[np.arange(y.size), y] = 1\n",
    "        return X_onehot, indexes\n",
    "\n",
    "    def minmax(self, X, min_X=None, max_X=None):\n",
    "        if min_X is None:\n",
    "            min_X = np.min(X, axis=0)\n",
    "        if max_X is None:\n",
    "            max_X = np.max(X, axis=0)\n",
    "        Z = (X - min_X) / (max_X - min_X)\n",
    "        return Z, min_X, max_X\n",
    "\n",
    "    def standardize(self, X, mu=None, std=None):\n",
    "        if mu is None:\n",
    "            mu = np.mean(X, axis=0)\n",
    "        if std is None:\n",
    "            std = np.std(X, axis=0)\n",
    "        Z = (X - mu) / std\n",
    "        return Z, mu, std\n",
    "\n",
    "    def inv_standardize(self, Z, mu, std):\n",
    "        X = Z * std + mu\n",
    "        return X\n",
    "\n",
    "    def train_test_split(self, X, y, test_ratio=0.2, seed=None):\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "        train_ratio = 1 - test_ratio\n",
    "        indices = np.random.permutation(X.shape[0])\n",
    "        train_idx, test_idx = (\n",
    "            indices[: int(train_ratio * len(X))],\n",
    "            indices[int(train_ratio * len(X)) :],\n",
    "        )\n",
    "        X_train, X_test = X[train_idx, :], X[test_idx, :]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1. Convolutional Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Padding2D:\n",
    "\n",
    "    def __init__(self, p=\"valid\"):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "\n",
    "        p: padding type\n",
    "        Allowed types are only 'same', 'valid', an integer or a tuple of length 2.\n",
    "        \"\"\"\n",
    "        self.p = p\n",
    "\n",
    "    def get_dimensions(self, input_shape, kernel_size, s=(1, 1)):\n",
    "        \"\"\"\n",
    "        Utility function to help get the dimension of the output after padding\n",
    "        \"\"\"\n",
    "        if len(input_shape) == 4:\n",
    "            m, Nc, Nh, Nw = input_shape\n",
    "        elif len(input_shape) == 3:\n",
    "            Nc, Nh, Nw = input_shape\n",
    "\n",
    "        Kh, Kw = kernel_size\n",
    "        sh, sw = s\n",
    "        p = self.p\n",
    "\n",
    "        if type(p) == int:\n",
    "            pt, pb = p, p\n",
    "            pl, pr = p, p\n",
    "\n",
    "        if type(p) == tuple:\n",
    "            ph, pw = p\n",
    "            pt, pb = ph // 2, (ph + 1) // 2\n",
    "            pl, pr = pw // 2, (pw + 1) // 2\n",
    "\n",
    "        elif p == \"valid\":\n",
    "            pt, pb = 0, 0\n",
    "            pl, pr = 0, 0\n",
    "\n",
    "        elif p == \"same\":\n",
    "            # calculating how much padding is required in all 4 directions\n",
    "            # (top, bottom, left and right)\n",
    "            ph = (sh - 1) * Nh + Kh - sh\n",
    "            pw = (sw - 1) * Nw + Kw - sw\n",
    "\n",
    "            pt, pb = ph // 2, (ph + 1) // 2\n",
    "            pl, pr = pw // 2, (pw + 1) // 2\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Incorrect padding type. Allowed types are only 'same', 'valid', an integer or a tuple of length 2.\"\n",
    "            )\n",
    "\n",
    "        if len(input_shape) == 4:\n",
    "            output_shape = (m, Nc, Nh + pt + pb, Nw + pl + pr)\n",
    "        elif len(input_shape) == 3:\n",
    "            output_shape = (Nc, Nh + pt + pb, Nw + pl + pr)\n",
    "\n",
    "        return output_shape, (pt, pb, pl, pr)\n",
    "\n",
    "    def forward(self, X, kernel_size, s=(1, 1)):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "\n",
    "        X: input of shape (m, Nc, Nh, Nw)\n",
    "\n",
    "        s: strides along height and width (sh, sw)\n",
    "\n",
    "        kernel_size: kernel size as specified in Conv2D layer\n",
    "\n",
    "        Returns:\n",
    "\n",
    "        Xp: padded X\n",
    "        \"\"\"\n",
    "        self.input_shape = X.shape\n",
    "        m, Nc, Nh, Nw = self.input_shape\n",
    "\n",
    "        self.output_shape, (self.pt, self.pb, self.pl, self.pr) = self.get_dimensions(\n",
    "            self.input_shape, kernel_size, s=s\n",
    "        )\n",
    "\n",
    "        zeros_r = np.zeros((m, Nc, Nh, self.pr))\n",
    "        zeros_l = np.zeros((m, Nc, Nh, self.pl))\n",
    "        zeros_t = np.zeros((m, Nc, self.pt, Nw + self.pl + self.pr))\n",
    "        zeros_b = np.zeros((m, Nc, self.pb, Nw + self.pl + self.pr))\n",
    "\n",
    "        Xp = np.concatenate((X, zeros_r), axis=3)\n",
    "        Xp = np.concatenate((zeros_l, Xp), axis=3)\n",
    "        Xp = np.concatenate((zeros_t, Xp), axis=2)\n",
    "        Xp = np.concatenate((Xp, zeros_b), axis=2)\n",
    "\n",
    "        return Xp\n",
    "\n",
    "    def backpropagation(self, dXp):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "\n",
    "        dXp: Backprop Error of padded X (Xp)\n",
    "\n",
    "        Return:\n",
    "\n",
    "        dX: Backprop Error of X\n",
    "        \"\"\"\n",
    "        m, Nc, Nh, Nw = self.input_shape\n",
    "        dX = dXp[:, :, self.pt : self.pt + Nh, self.pl : self.pl + Nw]\n",
    "        return dX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2D:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        filters,\n",
    "        kernel_size,\n",
    "        s=(1, 1),\n",
    "        p=\"valid\",\n",
    "        activation_type=None,\n",
    "        use_bias=True,\n",
    "        weight_initializer_type=None,\n",
    "        kernel_regularizer=None,\n",
    "        seed=None,\n",
    "        input_shape=None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "\n",
    "        filters: Integer, the number of output filters in the convolution (F).\n",
    "\n",
    "        kernel_size: An integer or tuple/list of 2 integers,\n",
    "                     specifying the height and width of the 2D convolution window.\n",
    "\n",
    "        s: strides along height and width (sh, sw)\n",
    "\n",
    "        p: padding type\n",
    "           Allowed types are only 'same', 'valid', an integer or a tuple of length 2.\n",
    "\n",
    "        activation_type: type of activation\n",
    "                         available options are 'sigmoid', 'linear', 'tanh', 'softmax', 'prelu' and 'relu'\n",
    "                         If you don't specify anything, no activation is applied (ie. \"linear\" activation: a(x) = x).\n",
    "\n",
    "        use_bias: Boolean, whether the layer uses a bias vector.\n",
    "\n",
    "        weight_initializer_type: Initializer for the kernel weights matrix.\n",
    "\n",
    "        kernel_regularizer: Tuple, Regularizer function applied to the kernel matrix ('L2', 0.01) or ('L1', 2)\n",
    "\n",
    "        seed: To generate reproducable results\n",
    "\n",
    "        input_shape: tuple showing size of input: (batch_size, channels, rows, cols) -> (m, Nc, Nh, Nw)\n",
    "        \"\"\"\n",
    "\n",
    "        self.padding = Padding2D(p=p)\n",
    "\n",
    "        self.F = filters\n",
    "\n",
    "        self.input_shape_x = input_shape\n",
    "\n",
    "        if type(kernel_size) == int:\n",
    "            self.kernel_size = (kernel_size, kernel_size)\n",
    "        elif type(kernel_size) == tuple and len(kernel_size) == 2:\n",
    "            self.kernel_size = kernel_size\n",
    "\n",
    "        self.Kh, self.Kw = self.kernel_size\n",
    "\n",
    "        if type(s) == int:\n",
    "            self.s = (s, s)\n",
    "        elif type(s) == tuple and len(s) == 2:\n",
    "            self.s = s\n",
    "\n",
    "        self.sh, self.sw = self.s\n",
    "\n",
    "        self.activation = Activation(activation_type=activation_type)\n",
    "        self.use_bias = use_bias\n",
    "        self.weight_initializer_type = weight_initializer_type  # none is handled\n",
    "        if kernel_regularizer is None:\n",
    "            self.kernel_regularizer = (\"L2\", 0)\n",
    "        else:\n",
    "            self.kernel_regularizer = kernel_regularizer\n",
    "        self.seed = seed\n",
    "\n",
    "    def get_dimensions(self, input_shape):\n",
    "\n",
    "        self.input_shape_x = input_shape  # (3D or 4D)\n",
    "\n",
    "        # Padded X will be actual input to this Conv2D\n",
    "\n",
    "        self.input_shape, _ = self.padding.get_dimensions(\n",
    "            self.input_shape_x, self.kernel_size, self.s\n",
    "        )\n",
    "\n",
    "        if len(input_shape) == 3:\n",
    "            self.Nc, self.Nh, self.Nw = self.input_shape\n",
    "        elif len(input_shape) == 4:\n",
    "            self.m, self.Nc, self.Nh, self.Nw = self.input_shape\n",
    "\n",
    "        # Output shape\n",
    "        self.Oh = (self.Nh - self.Kh) // self.sh + 1\n",
    "        self.Ow = (self.Nw - self.Kw) // self.sw + 1\n",
    "\n",
    "        if len(input_shape) == 3:\n",
    "            self.output_shape = (self.F, self.Oh, self.Ow)\n",
    "        elif len(input_shape) == 4:\n",
    "            self.output_shape = (self.m, self.F, self.Oh, self.Ow)\n",
    "\n",
    "    def initialize_parameters(self, input_shape, optimizer_type):\n",
    "\n",
    "        self.get_dimensions(input_shape)\n",
    "\n",
    "        shape_b = (self.F, self.Oh, self.Ow)\n",
    "\n",
    "        shape_K = (self.F, self.Nc, self.Kh, self.Kw)\n",
    "\n",
    "        initializer = Weights_initializer(\n",
    "            shape=shape_K, initializer_type=self.weight_initializer_type, seed=self.seed\n",
    "        )\n",
    "\n",
    "        self.K = initializer.get_initializer()\n",
    "        self.b = np.zeros(shape_b)\n",
    "\n",
    "        self.optimizer = Optimizer(\n",
    "            optimizer_type=optimizer_type, shape_W=shape_K, shape_b=shape_b\n",
    "        )\n",
    "\n",
    "    def dilate2D(self, X, Dr=(1, 1)):\n",
    "        dh, dw = Dr  # Dilate rate\n",
    "        m, C, H, W = X.shape\n",
    "        Xd = np.insert(arr=X, obj=np.repeat(np.arange(1, W), dw - 1), values=0, axis=-1)\n",
    "        Xd = np.insert(\n",
    "            arr=Xd, obj=np.repeat(np.arange(1, H), dh - 1), values=0, axis=-2\n",
    "        )\n",
    "        return Xd\n",
    "\n",
    "    def prepare_subMatrix(self, X, Kh, Kw, s):\n",
    "        m, Nc, Nh, Nw = X.shape\n",
    "        sh, sw = s\n",
    "\n",
    "        Oh = (Nh - Kh) // sh + 1\n",
    "        Ow = (Nw - Kw) // sw + 1\n",
    "\n",
    "        strides = (Nc * Nh * Nw, Nw * Nh, Nw * sh, sw, Nw, 1)\n",
    "        strides = tuple(i * X.itemsize for i in strides)\n",
    "\n",
    "        subM = np.lib.stride_tricks.as_strided(\n",
    "            X, shape=(m, Nc, Oh, Ow, Kh, Kw), strides=strides\n",
    "        )\n",
    "\n",
    "        return subM\n",
    "\n",
    "    def convolve(self, X, K, s=(1, 1), mode=\"front\"):\n",
    "\n",
    "        F, Kc, Kh, Kw = K.shape\n",
    "        subM = self.prepare_subMatrix(X, Kh, Kw, s)\n",
    "\n",
    "        if mode == \"front\":\n",
    "            return np.einsum(\"fckl,mcijkl->mfij\", K, subM)\n",
    "        elif mode == \"back\":\n",
    "            return np.einsum(\"fdkl,mcijkl->mdij\", K, subM)\n",
    "        elif mode == \"param\":\n",
    "            return np.einsum(\"mfkl,mcijkl->fcij\", K, subM)\n",
    "\n",
    "    def dZ_D_dX(self, dZ_D, Nh, Nw):\n",
    "\n",
    "        # Pad the dilated dZ (dZ_D -> dZ_Dp)\n",
    "\n",
    "        _, _, Hd, Wd = dZ_D.shape\n",
    "\n",
    "        ph = Nh - Hd + self.Kh - 1\n",
    "        pw = Nw - Wd + self.Kw - 1\n",
    "\n",
    "        padding_back = Padding2D(p=(ph, pw))\n",
    "\n",
    "        dZ_Dp = padding_back.forward(dZ_D, self.kernel_size, self.s)\n",
    "\n",
    "        # Rotate K by 180 degrees\n",
    "\n",
    "        K_rotated = self.K[:, :, ::-1, ::-1]\n",
    "\n",
    "        # convolve dZ_Dp with K_rotated\n",
    "\n",
    "        dXp = self.convolve(dZ_Dp, K_rotated, mode=\"back\")\n",
    "\n",
    "        dX = self.padding.backpropagation(dXp)\n",
    "\n",
    "        return dX\n",
    "\n",
    "    def forward(self, X):\n",
    "        # padding\n",
    "\n",
    "        self.X = X\n",
    "\n",
    "        Xp = self.padding.forward(X, self.kernel_size, self.s)\n",
    "\n",
    "        # convolve Xp with K\n",
    "        Z = self.convolve(Xp, self.K, self.s) + self.b\n",
    "\n",
    "        a = self.activation.forward(Z)\n",
    "\n",
    "        return a\n",
    "\n",
    "    def backpropagation(self, da):\n",
    "\n",
    "        Xp = self.padding.forward(self.X, self.kernel_size, self.s)\n",
    "\n",
    "        m, Nc, Nh, Nw = Xp.shape\n",
    "\n",
    "        dZ = self.activation.backpropagation(da)\n",
    "\n",
    "        # Dilate dZ (dZ-> dZ_D)\n",
    "\n",
    "        dZ_D = self.dilate2D(dZ, Dr=self.s)\n",
    "\n",
    "        dX = self.dZ_D_dX(dZ_D, Nh, Nw)\n",
    "\n",
    "        # Gradient dK\n",
    "\n",
    "        _, _, Hd, Wd = dZ_D.shape\n",
    "\n",
    "        ph = self.Nh - Hd - self.Kh + 1\n",
    "        pw = self.Nw - Wd - self.Kw + 1\n",
    "\n",
    "        padding_back = Padding2D(p=(ph, pw))\n",
    "\n",
    "        dZ_Dp = padding_back.forward(dZ_D, self.kernel_size, self.s)\n",
    "\n",
    "        self.dK = self.convolve(Xp, dZ_Dp, mode=\"param\")\n",
    "\n",
    "        # Gradient db\n",
    "\n",
    "        self.db = np.sum(dZ, axis=0)\n",
    "\n",
    "        return dX\n",
    "\n",
    "    def update(self, lr, m, k):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "\n",
    "        lr: learning rate\n",
    "        m: batch_size (sumber of samples in batch)\n",
    "        k: iteration_number\n",
    "        \"\"\"\n",
    "        dK, db = self.optimizer.get_optimization(self.dK, self.db, k)\n",
    "\n",
    "        if self.kernel_regularizer[0].lower() == \"l2\":\n",
    "            dK += self.kernel_regularizer[1] * self.K\n",
    "        elif self.weight_regularizer[0].lower() == \"l1\":\n",
    "            dK += self.kernel_regularizer[1] * np.sign(self.K)\n",
    "\n",
    "        self.K -= self.dK * (lr / m)\n",
    "\n",
    "        if self.use_bias:\n",
    "            self.b -= self.db * (lr / m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2. Pooling Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pooling2D:\n",
    "\n",
    "    def __init__(self, pool_size=(2, 2), s=(2, 2), p=\"valid\", pool_type=\"max\"):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "\n",
    "        pool_size: An integer or tuple/list of 2 integers,\n",
    "                     specifying the height and width of the 2D convolution window.\n",
    "\n",
    "        s: strides along height and width (sh, sw)\n",
    "\n",
    "        p: padding type\n",
    "           Allowed types are only 'same', 'valid', an integer or a tuple of length 2.\n",
    "\n",
    "        pool_type: pooling type\n",
    "        Allowed types are only 'max', or 'mean'\n",
    "        \"\"\"\n",
    "        self.padding = Padding2D(p=p)\n",
    "\n",
    "        if type(pool_size) == int:\n",
    "            self.pool_size = (pool_size, pool_size)\n",
    "        elif type(pool_size) == tuple and len(pool_size) == 2:\n",
    "            self.pool_size = pool_size\n",
    "\n",
    "        self.Kh, self.Kw = self.pool_size\n",
    "\n",
    "        if type(s) == int:\n",
    "            self.s = (s, s)\n",
    "        elif type(s) == tuple and len(s) == 2:\n",
    "            self.s = s\n",
    "\n",
    "        self.sh, self.sw = self.s\n",
    "\n",
    "        self.pool_type = pool_type\n",
    "\n",
    "    def get_dimensions(self, input_shape):\n",
    "\n",
    "        if len(input_shape) == 4:\n",
    "            m, Nc, Nh, Nw = input_shape\n",
    "        elif len(input_shape) == 3:\n",
    "            Nc, Nh, Nw = input_shape\n",
    "\n",
    "        Oh = (Nh - self.Kh) // self.sh + 1\n",
    "        Ow = (Nw - self.Kw) // self.sw + 1\n",
    "\n",
    "        if len(input_shape) == 4:\n",
    "            self.output_shape = (m, Nc, Oh, Ow)\n",
    "        elif len(input_shape) == 3:\n",
    "            self.output_shape = (Nc, Oh, Ow)\n",
    "\n",
    "    def prepare_subMatrix(self, X, pool_size, s):\n",
    "        m, Nc, Nh, Nw = X.shape\n",
    "        sh, sw = s\n",
    "        Kh, Kw = pool_size\n",
    "\n",
    "        Oh = (Nh - Kh) // sh + 1\n",
    "        Ow = (Nw - Kw) // sw + 1\n",
    "\n",
    "        strides = (Nc * Nh * Nw, Nh * Nw, Nw * sh, sw, Nw, 1)\n",
    "        strides = tuple(i * X.itemsize for i in strides)\n",
    "\n",
    "        subM = np.lib.stride_tricks.as_strided(\n",
    "            X, shape=(m, Nc, Oh, Ow, Kh, Kw), strides=strides\n",
    "        )\n",
    "        return subM\n",
    "\n",
    "    def pooling(self, X, pool_size=(2, 2), s=(2, 2)):\n",
    "\n",
    "        subM = self.prepare_subMatrix(X, pool_size, s)\n",
    "\n",
    "        if self.pool_type == \"max\":\n",
    "            return np.max(subM, axis=(-2, -1))\n",
    "        elif self.pool_type == \"mean\":\n",
    "            return np.mean(subM, axis=(-2, -1))\n",
    "        else:\n",
    "            raise ValueError(\"Allowed pool types are only 'max' or 'mean'.\")\n",
    "\n",
    "    def prepare_mask(self, subM, Kh, Kw):\n",
    "\n",
    "        m, Nc, Oh, Ow, Kh, Kw = subM.shape\n",
    "\n",
    "        a = subM.reshape(-1, Kh * Kw)\n",
    "        idx = np.argmax(a, axis=1)\n",
    "        b = np.zeros(a.shape)\n",
    "        b[np.arange(b.shape[0]), idx] = 1\n",
    "        mask = b.reshape((m, Nc, Oh, Ow, Kh, Kw))\n",
    "\n",
    "        return mask\n",
    "\n",
    "    def mask_dXp(self, mask, Xp, dZ, Kh, Kw):\n",
    "        dA = np.einsum(\"i,ijk->ijk\", dZ.reshape(-1), mask.reshape(-1, Kh, Kw)).reshape(\n",
    "            mask.shape\n",
    "        )\n",
    "        m, Nc, Nh, Nw = Xp.shape\n",
    "        strides = (Nc * Nh * Nw, Nh * Nw, Nw, 1)\n",
    "        strides = tuple(i * Xp.itemsize for i in strides)\n",
    "        dXp = np.lib.stride_tricks.as_strided(dA, Xp.shape, strides)\n",
    "        return dXp\n",
    "\n",
    "    def maxpool_backprop(self, dZ, X):\n",
    "\n",
    "        Xp = self.padding.forward(X, self.pool_size, self.s)\n",
    "\n",
    "        subM = self.prepare_subMatrix(Xp, self.pool_size, self.s)\n",
    "\n",
    "        m, Nc, Oh, Ow, Kh, Kw = subM.shape\n",
    "\n",
    "        m, Nc, Nh, Nw = Xp.shape\n",
    "\n",
    "        mask = self.prepare_mask(subM, Kh, Kw)\n",
    "\n",
    "        dXp = self.mask_dXp(mask, Xp, dZ, Kh, Kw)\n",
    "\n",
    "        return dXp\n",
    "\n",
    "    def dZ_dZp(self, dZ):\n",
    "        sh, sw = self.s\n",
    "        Kh, Kw = self.pool_size\n",
    "\n",
    "        dZp = np.kron(\n",
    "            dZ, np.ones((Kh, Kw), dtype=dZ.dtype)\n",
    "        )  # similar to repelem in matlab\n",
    "\n",
    "        jh, jw = Kh - sh, Kw - sw  # jump along height and width\n",
    "\n",
    "        if jw != 0:\n",
    "            L = dZp.shape[-1] - 1\n",
    "\n",
    "            l1 = np.arange(sw, L)\n",
    "            l2 = np.arange(sw + jw, L + jw)\n",
    "\n",
    "            mask = np.tile([True] * jw + [False] * jw, len(l1) // jw).astype(bool)\n",
    "\n",
    "            r1 = l1[mask[: len(l1)]]\n",
    "            r2 = l2[mask[: len(l2)]]\n",
    "\n",
    "            dZp[:, :, :, r1] += dZp[:, :, :, r2]\n",
    "            dZp = np.delete(dZp, r2, axis=-1)\n",
    "\n",
    "        if jh != 0:\n",
    "            L = dZp.shape[-2] - 1\n",
    "\n",
    "            l1 = np.arange(sh, L)\n",
    "            l2 = np.arange(sh + jh, L + jh)\n",
    "\n",
    "            mask = np.tile([True] * jh + [False] * jh, len(l1) // jh).astype(bool)\n",
    "\n",
    "            r1 = l1[mask[: len(l1)]]\n",
    "            r2 = l2[mask[: len(l2)]]\n",
    "\n",
    "            dZp[:, :, r1, :] += dZp[:, :, r2, :]\n",
    "            dZp = np.delete(dZp, r2, axis=-2)\n",
    "\n",
    "        return dZp\n",
    "\n",
    "    def averagepool_backprop(self, dZ, X):\n",
    "\n",
    "        Xp = self.padding.forward(X, self.pool_size, self.s)\n",
    "\n",
    "        m, Nc, Nh, Nw = Xp.shape\n",
    "\n",
    "        dZp = self.dZ_dZp(dZ)\n",
    "\n",
    "        ph = Nh - dZp.shape[-2]\n",
    "        pw = Nw - dZp.shape[-1]\n",
    "\n",
    "        padding_back = Padding2D(p=(ph, pw))\n",
    "\n",
    "        dXp = padding_back.forward(dZp, s=self.s, kernel_size=self.pool_size)\n",
    "\n",
    "        return dXp / (Nh * Nw)\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "\n",
    "        X: input of shape (m, Nc, Nh, Nw)\n",
    "\n",
    "        Returns:\n",
    "\n",
    "        Z: pooled X\n",
    "        \"\"\"\n",
    "\n",
    "        self.X = X\n",
    "\n",
    "        # padding\n",
    "        Xp = self.padding.forward(X, self.pool_size, self.s)\n",
    "\n",
    "        Z = self.pooling(Xp, self.pool_size, self.s)\n",
    "\n",
    "        return Z\n",
    "\n",
    "    def backpropagation(self, dZ):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "\n",
    "        dZ: Output Error\n",
    "\n",
    "        Return:\n",
    "\n",
    "        dX: Backprop Error of X\n",
    "        \"\"\"\n",
    "        if self.pool_type == \"max\":\n",
    "            dXp = self.maxpool_backprop(dZ, self.X)\n",
    "        elif self.pool_type == \"mean\":\n",
    "            dXp = self.averagepool_backprop(dZ, self.X)\n",
    "        dX = self.padding.backpropagation(dXp)\n",
    "        return dX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3. Flatten Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten:\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.m, self.Nc, self.Nh, self.Nw = X.shape\n",
    "        X_flat = X.reshape((self.m, self.Nc * self.Nh * self.Nw))\n",
    "        return X_flat\n",
    "\n",
    "    def backpropagation(self, dZ):\n",
    "        dX = dZ.reshape((self.m, self.Nc, self.Nh, self.Nw))\n",
    "        return dX\n",
    "\n",
    "    def get_dimensions(self, input_shape):\n",
    "\n",
    "        if len(input_shape) == 4:\n",
    "            self.m, self.Nc, self.Nh, self.Nw = input_shape\n",
    "        elif len(input_shape) == 3:\n",
    "            self.Nc, self.Nh, self.Nw = input_shape\n",
    "\n",
    "        self.output_shape = self.Nc * self.Nh * self.Nw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.4. Dense Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        neurons,\n",
    "        activation_type=None,\n",
    "        use_bias=True,\n",
    "        weight_initializer_type=None,\n",
    "        weight_regularizer=None,\n",
    "        seed=None,\n",
    "        input_dim=None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "\n",
    "        neurons: Positive integer (number of neurons), dimensionality of the output\n",
    "\n",
    "        activation_type: type of activation\n",
    "                         available options are 'sigmoid', 'linear', 'tanh', 'softmax', 'prelu' and 'relu'\n",
    "                         If you don't specify anything, no activation is applied (ie. \"linear\" activation: a(x) = x).\n",
    "\n",
    "        use_bias: Boolean, whether the layer uses a bias vector.\n",
    "\n",
    "        weight_initializer_type: Initializer for the kernel weights matrix.\n",
    "\n",
    "        weight_regularizer: Tuple, Regularizer function applied to the weights matrix ('L2', 0.01) or ('L1', 2)\n",
    "\n",
    "        seed: To generate reproducable results\n",
    "\n",
    "        input_dim: integer showing number of neurons in input layer\n",
    "        \"\"\"\n",
    "        self.neurons = neurons\n",
    "        self.activation = Activation(activation_type=activation_type)\n",
    "        self.use_bias = use_bias\n",
    "        self.weight_initializer_type = weight_initializer_type  # none is handled\n",
    "        if weight_regularizer is None:\n",
    "            self.weight_regularizer = (\"L2\", 0)\n",
    "        else:\n",
    "            self.weight_regularizer = weight_regularizer\n",
    "        self.seed = seed\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "    def initialize_parameters(self, hl, optimizer_type):\n",
    "        \"\"\"\n",
    "        hl: Number of neurons in layer l-1\n",
    "        \"\"\"\n",
    "        shape_W = (hl, self.neurons)\n",
    "        shape_b = (self.neurons, 1)\n",
    "        initializer = Weights_initializer(\n",
    "            shape=shape_W, initializer_type=self.weight_initializer_type, seed=self.seed\n",
    "        )\n",
    "        self.W = initializer.get_initializer()\n",
    "        self.b = np.zeros(shape_b)\n",
    "\n",
    "        self.optimizer = Optimizer(\n",
    "            optimizer_type=optimizer_type, shape_W=shape_W, shape_b=shape_b\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.X = X\n",
    "        r = X @ self.W\n",
    "        self.z = r + self.b.T\n",
    "        a = self.activation.forward(self.z)\n",
    "        return a\n",
    "\n",
    "    def backpropagation(self, da):\n",
    "        dz = self.activation.backpropagation(da)\n",
    "        dr = dz.copy()\n",
    "        self.db = np.sum(dz, axis=0).reshape(-1, 1)\n",
    "        self.dW = (self.X.T) @ dr\n",
    "        dX = dr @ (self.W.T)\n",
    "        return dX\n",
    "\n",
    "    def update(self, lr, m, k):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "\n",
    "        lr: learning rate\n",
    "        m: batch_size (sumber of samples in batch)\n",
    "        k: iteration_number\n",
    "        \"\"\"\n",
    "        dW, db = self.optimizer.get_optimization(self.dW, self.db, k)\n",
    "\n",
    "        if self.weight_regularizer[0].lower() == \"l2\":\n",
    "            dW += self.weight_regularizer[1] * self.W\n",
    "        elif self.weight_regularizer[0].lower() == \"l1\":\n",
    "            dW += self.weight_regularizer[1] * np.sign(self.W)\n",
    "\n",
    "        self.W -= dW * (lr / m)\n",
    "        if self.use_bias:\n",
    "            self.b -= db * (lr / m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.5. Dropout Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dropout:\n",
    "\n",
    "    def __init__(self, p):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "\n",
    "        p: Dropout probability\n",
    "        \"\"\"\n",
    "        self.p = p\n",
    "        if self.p == 0:\n",
    "            self.p += 1e-6\n",
    "        if self.p == 1:\n",
    "            self.p -= 1e-6\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.mask = (np.random.rand(*X.shape) < self.p) / self.p\n",
    "        Z = X * self.mask\n",
    "        return Z\n",
    "\n",
    "    def backpropagation(self, dZ):\n",
    "        dX = dZ * self.mask\n",
    "        return dX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.7. CNN class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN:\n",
    "\n",
    "    def __init__(self, layers=None):\n",
    "        \"\"\"\n",
    "        This is a sequential CNN model\n",
    "        \"\"\"\n",
    "        if layers is None:\n",
    "            self.layers = []\n",
    "        else:\n",
    "            self.layers = layers\n",
    "        self.network_architecture_called = False\n",
    "\n",
    "    def add(self, layer):\n",
    "        # adds a layer to CNN model\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    def Input(self, input_shape):\n",
    "        self.d = input_shape\n",
    "        self.architecture = [self.d]  # output architecture\n",
    "        self.layer_name = [\"Input\"]\n",
    "\n",
    "    def network_architecture(self):\n",
    "        for layer in self.layers:\n",
    "            if layer.__class__.__name__ == \"Conv2D\":\n",
    "                if layer.input_shape_x is not None:\n",
    "                    self.Input(layer.input_shape_x)\n",
    "                layer.get_dimensions(self.architecture[-1])\n",
    "                self.architecture.append(layer.output_shape)\n",
    "                self.layer_name.append(layer.__class__.__name__)\n",
    "            elif layer.__class__.__name__ in [\"Flatten\", \"Pooling2D\"]:\n",
    "                layer.get_dimensions(self.architecture[-1])\n",
    "                self.architecture.append(layer.output_shape)\n",
    "                self.layer_name.append(layer.__class__.__name__)\n",
    "            elif layer.__class__.__name__ == \"Dense\":\n",
    "                self.architecture.append(layer.neurons)\n",
    "                self.layer_name.append(layer.__class__.__name__)\n",
    "            else:\n",
    "                self.architecture.append(self.architecture[-1])\n",
    "                self.layer_name.append(layer.__class__.__name__)\n",
    "\n",
    "        self.layers = [layer for layer in self.layers if layer is not None]\n",
    "        try:\n",
    "            idx = model.layer_name.index(\"NoneType\")\n",
    "            del model.layer_name[idx]\n",
    "            del model.architecture[idx]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    def summary(self):\n",
    "        if self.network_architecture_called == False:\n",
    "            self.network_architecture()\n",
    "            self.network_architecture_called = True\n",
    "        len_assigned = [45, 26, 15]\n",
    "        count = {\n",
    "            \"Dense\": 1,\n",
    "            \"Activation\": 1,\n",
    "            \"Input\": 1,\n",
    "            \"BatchNormalization\": 1,\n",
    "            \"Dropout\": 1,\n",
    "            \"Conv2D\": 1,\n",
    "            \"Pooling2D\": 1,\n",
    "            \"Flatten\": 1,\n",
    "        }\n",
    "\n",
    "        col_names = [\"Layer (type)\", \"Output Shape\", \"# of Parameters\"]\n",
    "\n",
    "        print(\"Model: CNN\")\n",
    "        print(\"-\" * sum(len_assigned))\n",
    "\n",
    "        text = \"\"\n",
    "        for i in range(3):\n",
    "            text += col_names[i] + \" \" * (len_assigned[i] - len(col_names[i]))\n",
    "        print(text)\n",
    "\n",
    "        print(\"=\" * sum(len_assigned))\n",
    "\n",
    "        total_params = 0\n",
    "        trainable_params = 0\n",
    "        non_trainable_params = 0\n",
    "\n",
    "        for i in range(len(self.layer_name)):\n",
    "            # layer name\n",
    "            layer_name = self.layer_name[i]\n",
    "            name = (\n",
    "                layer_name.lower()\n",
    "                + \"_\"\n",
    "                + str(count[layer_name])\n",
    "                + \" \"\n",
    "                + \"(\"\n",
    "                + layer_name\n",
    "                + \")\"\n",
    "            )\n",
    "            count[layer_name] += 1\n",
    "\n",
    "            # output shape\n",
    "            try:\n",
    "                out = \"(None, \"\n",
    "                for n in range(len(model.architecture[i]) - 1):\n",
    "                    out += str(model.architecture[i][n]) + \", \"\n",
    "                out += str(model.architecture[i][-1]) + \")\"\n",
    "            except:\n",
    "                out = \"(None, \" + str(self.architecture[i]) + \")\"\n",
    "\n",
    "            # number of params\n",
    "            if layer_name == \"Dense\":\n",
    "                h0 = self.architecture[i - 1]\n",
    "                h1 = self.architecture[i]\n",
    "                if self.layers[i - 1].use_bias:\n",
    "                    params = h0 * h1 + h1\n",
    "                else:\n",
    "                    params = h0 * h1\n",
    "                total_params += params\n",
    "                trainable_params += params\n",
    "            elif layer_name == \"BatchNormalization\":\n",
    "                h = self.architecture[i]\n",
    "                params = 4 * h\n",
    "                trainable_params += 2 * h\n",
    "                non_trainable_params += 2 * h\n",
    "                total_params += params\n",
    "            elif layer_name == \"Conv2D\":\n",
    "                layer = self.layers[i - 1]\n",
    "                if layer.use_bias:\n",
    "                    add_b = 1\n",
    "                else:\n",
    "                    add_b = 0\n",
    "                params = ((layer.Nc * layer.Kh * layer.Kw) + add_b) * layer.F\n",
    "                trainable_params += params\n",
    "                total_params += params\n",
    "            else:\n",
    "                # Pooling, Dropout, Flatten, Input\n",
    "                params = 0\n",
    "            names = [name, out, str(params)]\n",
    "\n",
    "            # print this row\n",
    "            text = \"\"\n",
    "            for j in range(3):\n",
    "                text += names[j] + \" \" * (len_assigned[j] - len(names[j]))\n",
    "            print(text)\n",
    "            if i != (len(self.layer_name) - 1):\n",
    "                print(\"-\" * sum(len_assigned))\n",
    "            else:\n",
    "                print(\"=\" * sum(len_assigned))\n",
    "\n",
    "        print(\"Total params:\", total_params)\n",
    "        print(\"Trainable params:\", trainable_params)\n",
    "        print(\"Non-trainable params:\", non_trainable_params)\n",
    "        print(\"-\" * sum(len_assigned))\n",
    "\n",
    "    def compile(self, cost_type, optimizer_type):\n",
    "        self.cost = Cost(cost_type)\n",
    "        self.cost_type = cost_type\n",
    "        self.optimizer_type = optimizer_type\n",
    "\n",
    "    def initialize_parameters(self):\n",
    "        if self.network_architecture_called == False:\n",
    "            self.network_architecture()\n",
    "            self.network_architecture_called = True\n",
    "        # initialize parameters for different layers\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            if layer.__class__.__name__ in [\"Dense\", \"Conv2D\"]:\n",
    "                layer.initialize_parameters(self.architecture[i], self.optimizer_type)\n",
    "            elif layer.__class__.__name__ == \"BatchNormalization\":\n",
    "                layer.initialize_parameters(self.architecture[i])\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        X,\n",
    "        y,\n",
    "        epochs=10,\n",
    "        batch_size=5,\n",
    "        lr=1,\n",
    "        X_val=None,\n",
    "        y_val=None,\n",
    "        verbose=1,\n",
    "        lr_decay=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "\n",
    "        self.history = {\n",
    "            \"Training Loss\": [],\n",
    "            \"Validation Loss\": [],\n",
    "            \"Training Accuracy\": [],\n",
    "            \"Validation Accuracy\": [],\n",
    "        }\n",
    "\n",
    "        iterations = 0\n",
    "        self.m = batch_size\n",
    "        self.initialize_parameters()\n",
    "\n",
    "        total_num_batches = np.ceil(len(X) / batch_size)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            cost_train = 0\n",
    "            num_batches = 0\n",
    "            y_pred_train = []\n",
    "            y_train = []\n",
    "\n",
    "            print(\"\\nEpoch: \" + str(epoch + 1) + \"/\" + str(epochs))\n",
    "\n",
    "            for i in tqdm(range(0, len(X), batch_size)):\n",
    "                X_batch = X[i : i + batch_size]\n",
    "                y_batch = y[i : i + batch_size]\n",
    "\n",
    "                Z = X_batch.copy()\n",
    "\n",
    "                # feed-forward\n",
    "                for layer in self.layers:\n",
    "                    Z = layer.forward(Z)\n",
    "\n",
    "                # calculating training accuracy\n",
    "                if self.cost_type == \"cross-entropy\":\n",
    "                    y_pred_train += np.argmax(Z, axis=1).tolist()\n",
    "                    y_train += np.argmax(y_batch, axis=1).tolist()\n",
    "\n",
    "                # calculating the loss\n",
    "                cost_train += self.cost.get_cost(Z, y_batch) / self.m\n",
    "\n",
    "                # calculating dL/daL (last layer backprop error)\n",
    "                dZ = self.cost.get_d_cost(Z, y_batch)\n",
    "\n",
    "                # backpropagation\n",
    "                for layer in self.layers[::-1]:\n",
    "                    dZ = layer.backpropagation(dZ)\n",
    "\n",
    "                # Parameters update\n",
    "                for layer in self.layers:\n",
    "                    if layer.__class__.__name__ in [\n",
    "                        \"Dense\",\n",
    "                        \"BatchNormalization\",\n",
    "                        \"Conv2D\",\n",
    "                    ]:\n",
    "                        layer.update(lr, self.m, iterations)\n",
    "\n",
    "                # Learning rate decay\n",
    "                if lr_decay is not None:\n",
    "                    lr = lr_decay(iterations, **kwargs)\n",
    "\n",
    "                num_batches += 1\n",
    "                iterations += 1\n",
    "\n",
    "            cost_train /= num_batches\n",
    "\n",
    "            # printing purpose only (Training Accuracy, Validation loss and accuracy)\n",
    "\n",
    "            text = \"Training Loss: \" + str(round(cost_train, 4)) + \" - \"\n",
    "            self.history[\"Training Loss\"].append(cost_train)\n",
    "\n",
    "            # training accuracy\n",
    "\n",
    "            if self.cost_type == \"cross-entropy\":\n",
    "                accuracy_train = np.sum(\n",
    "                    np.array(y_pred_train) == np.array(y_train)\n",
    "                ) / len(y_train)\n",
    "                text += \"Training Accuracy: \" + str(round(accuracy_train, 4))\n",
    "                self.history[\"Training Accuracy\"].append(accuracy_train)\n",
    "            else:\n",
    "                text += \"Training Accuracy: \" + str(round(cost_train, 4))\n",
    "                self.history[\"Training Accuracy\"].append(cost_train)\n",
    "\n",
    "            if X_val is not None:\n",
    "                cost_val, accuracy_val = self.evaluate(X_val, y_val, batch_size)\n",
    "                text += \" - Validation Loss: \" + str(round(cost_val, 4)) + \" - \"\n",
    "                self.history[\"Validation Loss\"].append(cost_val)\n",
    "                text += \"Validation Accuracy: \" + str(round(accuracy_val, 4))\n",
    "                self.history[\"Validation Accuracy\"].append(accuracy_val)\n",
    "\n",
    "            if verbose:\n",
    "                print(text)\n",
    "            else:\n",
    "                print()\n",
    "\n",
    "    def evaluate(self, X, y, batch_size=None):\n",
    "\n",
    "        if batch_size is None:\n",
    "            batch_size = len(X)\n",
    "\n",
    "        cost = 0\n",
    "        correct = 0\n",
    "        num_batches = 0\n",
    "        utility = Utility()\n",
    "        Y_1hot, _ = utility.onehot(y)\n",
    "\n",
    "        for i in range(0, len(X), batch_size):\n",
    "            X_batch = X[i : i + batch_size]\n",
    "            y_batch = y[i : i + batch_size]\n",
    "            Y_1hot_batch = Y_1hot[i : i + batch_size]\n",
    "            Z = X_batch.copy()\n",
    "            for layer in self.layers:\n",
    "                if layer.__class__.__name__ == \"BatchNormalization\":\n",
    "                    Z = layer.forward(Z, mode=\"test\")\n",
    "                else:\n",
    "                    Z = layer.forward(Z)\n",
    "            if self.cost_type == \"cross-entropy\":\n",
    "                cost += self.cost.get_cost(Z, Y_1hot_batch) / len(y_batch)\n",
    "                y_pred = np.argmax(Z, axis=1).tolist()\n",
    "                correct += np.sum(y_pred == y_batch)\n",
    "            else:\n",
    "                cost += self.cost.get_cost(Z, y_batch) / len(y_batch)\n",
    "\n",
    "            num_batches += 1\n",
    "\n",
    "        if self.cost_type == \"cross-entropy\":\n",
    "            accuracy = correct / len(y)\n",
    "            cost /= num_batches\n",
    "            return cost, accuracy\n",
    "        else:\n",
    "            cost /= num_batches\n",
    "            return cost, cost\n",
    "\n",
    "    def loss_plot(self):\n",
    "        plt.plot(self.history[\"Training Loss\"], \"k\")\n",
    "        if len(self.history[\"Validation Loss\"]) > 0:\n",
    "            plt.plot(self.history[\"Validation Loss\"], \"r\")\n",
    "            plt.legend([\"Train\", \"Validation\"], loc=\"upper right\")\n",
    "            plt.title(\"Model Loss\")\n",
    "        else:\n",
    "            plt.title(\"Training Loss\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.show()\n",
    "\n",
    "    def accuracy_plot(self):\n",
    "        plt.plot(self.history[\"Training Accuracy\"], \"k\")\n",
    "        if len(self.history[\"Validation Accuracy\"]) > 0:\n",
    "            plt.plot(self.history[\"Validation Accuracy\"], \"r\")\n",
    "            plt.legend([\"Train\", \"Validation\"], loc=\"lower right\")\n",
    "            plt.title(\"Model Accuracy\")\n",
    "        else:\n",
    "            plt.title(\"Training Accuracy\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.show()\n",
    "\n",
    "    def predict(self, X, batch_size=None):\n",
    "\n",
    "        if batch_size == None:\n",
    "            batch_size = len(X)\n",
    "\n",
    "        for i in range(0, len(X), batch_size):\n",
    "            X_batch = X[i : i + batch_size]\n",
    "            Z = X_batch.copy()\n",
    "            for layer in self.layers:\n",
    "                if layer.__class__.__name__ == \"BatchNormalization\":\n",
    "                    Z = layer.forward(Z, mode=\"test\")\n",
    "                else:\n",
    "                    Z = layer.forward(Z)\n",
    "            if i == 0:\n",
    "                if self.cost_type == \"cross-entropy\":\n",
    "                    y_pred = np.argmax(Z, axis=1).tolist()\n",
    "                else:\n",
    "                    y_pred = Z\n",
    "            else:\n",
    "                if self.cost_type == \"cross-entropy\":\n",
    "                    y_pred += np.argmax(Z, axis=1).tolist()\n",
    "                else:\n",
    "                    y_pred = np.vstack((y_pred, Z))\n",
    "\n",
    "        return np.array(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 28, 28), 10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1], X_train.shape[2])\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1], X_test.shape[2])\n",
    "\n",
    "samples = 5000\n",
    "\n",
    "X_train = X_train[:samples, :] / 255\n",
    "X_test = X_test[:samples, :] / 255\n",
    "\n",
    "y_train = y_train[:samples]\n",
    "y_test = y_test[:samples]\n",
    "\n",
    "utility = Utility()\n",
    "\n",
    "# train validation split\n",
    "X_train_new, X_val, y_train_new, y_val = utility.train_test_split(\n",
    "    X_train, y_train, test_ratio=0.2, seed=42\n",
    ")\n",
    "\n",
    "Y_1hot_train, _ = utility.onehot(y_train_new)\n",
    "\n",
    "input_shape = X_train_new.shape[1:]\n",
    "output_dim = Y_1hot_train.shape[1]\n",
    "\n",
    "input_shape, output_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "\n",
    "model.add(model.Input(input_shape=input_shape))\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(5, 5), p=\"same\", activation_type=\"relu\"))\n",
    "\n",
    "model.add(Pooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(output_dim, activation_type=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: CNN\n",
      "--------------------------------------------------------------------------------------\n",
      "Layer (type)                                 Output Shape              # of Parameters\n",
      "======================================================================================\n",
      "input_1 (Input)                              (None, 1, 28, 28)         0              \n",
      "--------------------------------------------------------------------------------------\n",
      "conv2d_1 (Conv2D)                            (None, 32, 28, 28)        832            \n",
      "--------------------------------------------------------------------------------------\n",
      "pooling2d_1 (Pooling2D)                      (None, 32, 14, 14)        0              \n",
      "--------------------------------------------------------------------------------------\n",
      "flatten_1 (Flatten)                          (None, 6272)              0              \n",
      "--------------------------------------------------------------------------------------\n",
      "dropout_1 (Dropout)                          (None, 6272)              0              \n",
      "--------------------------------------------------------------------------------------\n",
      "dense_1 (Dense)                              (None, 10)                62730          \n",
      "======================================================================================\n",
      "Total params: 63562\n",
      "Trainable params: 63562\n",
      "Non-trainable params: 0\n",
      "--------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "epochs = 10\n",
    "lr = 0.05\n",
    "\n",
    "model.compile(cost_type=\"cross-entropy\", optimizer_type=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [03:32<00:00, 13.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 2.2061 - Training Accuracy: 0.3025 - Validation Loss: 1.6472 - Validation Accuracy: 0.454\n",
      "\n",
      "Epoch: 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [03:30<00:00, 13.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3552 - Training Accuracy: 0.535 - Validation Loss: 1.121 - Validation Accuracy: 0.648\n",
      "\n",
      "Epoch: 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [03:20<00:00, 12.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.0117 - Training Accuracy: 0.6577 - Validation Loss: 0.9004 - Validation Accuracy: 0.694\n",
      "\n",
      "Epoch: 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [03:18<00:00, 12.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.7985 - Training Accuracy: 0.727 - Validation Loss: 0.7702 - Validation Accuracy: 0.751\n",
      "\n",
      "Epoch: 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [03:20<00:00, 12.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.6912 - Training Accuracy: 0.766 - Validation Loss: 0.677 - Validation Accuracy: 0.77\n",
      "\n",
      "Epoch: 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [03:26<00:00, 12.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.6056 - Training Accuracy: 0.7988 - Validation Loss: 0.6384 - Validation Accuracy: 0.799\n",
      "\n",
      "Epoch: 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [03:26<00:00, 12.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.5665 - Training Accuracy: 0.81 - Validation Loss: 0.572 - Validation Accuracy: 0.806\n",
      "\n",
      "Epoch: 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [03:29<00:00, 13.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.5072 - Training Accuracy: 0.8355 - Validation Loss: 0.5284 - Validation Accuracy: 0.839\n",
      "\n",
      "Epoch: 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [03:19<00:00, 12.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4754 - Training Accuracy: 0.8448 - Validation Loss: 0.5172 - Validation Accuracy: 0.843\n",
      "\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [03:17<00:00, 12.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4364 - Training Accuracy: 0.8615 - Validation Loss: 0.501 - Validation Accuracy: 0.853\n"
     ]
    }
   ],
   "source": [
    "LR_decay = LearningRateDecay()\n",
    "\n",
    "model.fit(\n",
    "    X_train_new,\n",
    "    Y_1hot_train,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    lr=lr,\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    "    verbose=1,\n",
    "    lr_decay=LR_decay.constant,\n",
    "    lr_0=lr,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.loss_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.accuracy_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvIAAAGICAYAAAAjygR2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA98klEQVR4nO3de5xN9f7H8fdgjGGGKWHGLbeTS0ROJ6Ejlw5KkThdOEm5nPpVVKdSUZRLJaQ6JZHLoU6kkpxQYkq5pYyTSwrJdSLkPmaY/ftjnYzx/U72zOzZe39nv56Ph0fmbV0+q8f+Wh9rr+9aUT6fzycAAAAATikS6gIAAAAA5B6NPAAAAOAgGnkAAADAQTTyAAAAgINo5AEAAAAH0cgDAAAADqKRBwAAABxUzJ+FMjMztWvXLsXHxysqKqqga0Ih5fP5dPjwYVWsWFFFirj7b0jGAwKhsIwHiTGB/GM8AFlyMx78auR37dqlKlWqBKQ4YPv27apcuXKoy8gzxgMCyfXxIDEmEDiMByCLP+PBr3/2xsfHB6QgQHL/8+R6/QgvheHzVBiOAeGhMHyWCsMxIDz481nyq5HnqyEEkuufJ9frR3gpDJ+nwnAMCA+F4bNUGI4B4cGfz5LbN6IBAAAAEYpGHgAAAHAQjTwAAADgIBp5AAAAwEE08gAAAICDaOQBAAAAB9HIAwAAAA7y682uCKypU6da8/POO8/I7rvvPiP76aefAl4TAAAA3MIVeQAAAMBBNPIAAACAg2jkAQAAAAfRyAMAAAAOopEHAAAAHMRTawrYBRdcYGRXXnmlddlq1aoZ2TfffGNkQ4YMyW9ZAAAAcBxX5AEAAAAH0cgDAAAADqKRBwAAABxEIw8AAAA4iMmuBaxhw4ZGZpvUKknp6elGNnfu3ECXBAAAgEKAK/IAAACAg2jkAQAAAAfRyAMAAAAOopEHAAAAHMRk1wAqVsz83zllyhS/1//kk0+MbNWqVfkpCQAAwG8xMTFG9vDDDxtZfHy8df0mTZoY2UcffWRkY8eONTLbQz/w+7giDwAAADiIRh4AAABwEI08AAAA4CAaeQAAAMBBTHYNoHvvvdfIKlas6Pf63bt3D2Q5AIAQueCCC4ysW7duRmY7b9SqVcu6zW3bthnZO++8Y2QjR440sr1791q3ichWqVIlIxs9erSR3XTTTUb266+/WreZkJBgZC1atDCy2rVrG5ltPBw/fty6H3i4Ig8AAAA4iEYeAAAAcBCNPAAAAOAgGnkAAADAQUx2DaA+ffr4tdyOHTus+bFjxwJZDgAggMqXL2/NbZNYBw0aZGTnnXeeX/vZvXu3Nf/73/9uZImJiUZWr149I/vss8/82jciy7Rp04ysZcuWRjZ//nwje+SRR6zb7Nevn5H17t3byO644w4jmzdvnpHNmjXLuh94uCIPAAAAOIhGHgAAAHAQjTwAAADgIBp5AAAAwEE08gAAAICDeGpNHt19991GZnutdmpqqpG1a9fOus1Tp07lvzAAQK5ER0cb2T/+8Q8jsz01RpKqVq1qZCdPnjSyL7/80sguvfRSI7M9iUaSJk6caGTvvPOOkS1cuNC6PiJXnTp1rHmjRo38Wn/z5s1GtnbtWuuy9913n5EtXbrUyCZNmmRk48aNM7JffvnFup/k5GRrHmm4Ig8AAAA4iEYeAAAAcBCNPAAAAOAgGnkAAADAQUx29UOxYub/pi5duvi13FdffWVk3333XWAKAwDkSlJSkpHZXlPfqlUrv7c5efJkI7O9vn7//v1GlpCQYGSXXXaZdT+33nqrkfXv39/ImjdvbmTdu3c3sk2bNln3g8LniiuusOa2z5/N+vXr/d7XiRMnjOztt9/2a13bBNinnnrKuqztwSFpaWl+7acw4Yo8AAAA4CAaeQAAAMBBNPIAAACAg2jkAQAAAAdF+Xw+37kWOnTokMqUKROMesLSVVddZWSLFi0yMtub/GzrLl++3LqfqKgoI7O9cbBevXpGlpKSYt1mODp48KBKly4d6jLyLNLHAwLL9fEguTUmhg4damSDBg0yMtup8cMPP7Ru869//auRpaen56G63LO9mXPq1KlGtmPHDiPr0KFDQZSUL4yH/KtWrZqRrVu3zrpsbGyskX3wwQdGZvuM23qe3IiJiTGyL774wsj++Mc/Wtd/+umnjWzIkCH5qinc+DMeuCIPAAAAOIhGHgAAAHAQjTwAAADgIBp5AAAAwEG82dUPU6ZM8Ws52ySqnCa22nTt2tXIbG9DO3LkiJHZ3uS3du1av/eNgnHTTTdZ859++smv9evXr29ktokvp06dsq6/YsUKI9u6dauRZWRkGFmRIvZ/59esWdPIbG/Tq1u3rpHZ3qp5+eWXW/fz66+/GtlFF11kZJ988omRjRs3zq8aJftbCFF42SaCNm7c2Mjat29vZG+99ZZ1m8Ga2Gpje9BBp06djOzzzz83sscee8y6zWeeeSbfdSF0bG+Zt01qzcmxY8eMLL8TW21sf/fecccdRrZ48WLr+o8//riRPf/880ZmO7+FcswGGlfkAQAAAAfRyAMAAAAOopEHAAAAHEQjDwAAADiIRh4AAABwEE+tOUOvXr2seWJiopGtXr3ayEaPHp2v/U+fPj1f6yP8tG3b1prbngrQu3dvv7Zpe611VFRU7go7y8GDB42sRIkS1mWLFi1qZKmpqUZWuXJlv/admZlpzW1PFbDV2bBhQyPr37+/kc2YMcO6n/vvv/8cFaIw2bRpk5HZnopRrlw5I3v//fcLpKZAsz2Z6uOPPzYy2xOogFCyPW3P9vQ+SbrnnnuM7PDhw0a2fft2I7vwwgvzUF144oo8AAAA4CAaeQAAAMBBNPIAAACAg2jkAQAAAAdF7GTXiy++2MjGjx9vXdY2kdA2sfX48eNGVrFiRSPLaVKtbRKhzbPPPmtktgkiCD1/J7BKUr9+/fxarmXLlkaWkJDg93781ahRI2u+ceNGI1uxYoWRXXLJJX7tZ+/evdb8yy+/NLLSpUsbme0V9dWqVTOynP7/MtkVXbt2NbJFixYZWWF6rTuQE9vfs9HR0UaWkZERjHKsk7dz4/zzzzeyK664wsiWL1+er/2EClfkAQAAAAfRyAMAAAAOopEHAAAAHEQjDwAAADgoYie7Dhw40MhyejumbYKTbSLf3//+dyO76KKLjKxChQr+lJgj2wTKdu3aGVlaWpp1/alTpxqZbbLXrFmzjOyHH36wbnPVqlXWHIGXnJwclP3Mnj07X+tv2bIlX+vXqVPHyCZMmGBktomtNu+9916+6kHhYHujY5MmTYzs+eefD0Y5QdOpUycj69GjRwgqQUGznfv37dtnXbZs2bJG1qFDByMbNmyYkc2ZM8e6zd27dxuZ7cEfNt27d/cry424uDgjq169upEx2RUAAABA0NDIAwAAAA6ikQcAAAAcRCMPAAAAOCgiJrv+7W9/M7KbbrrJ7/WLFy9uZI888ki+asoP2+Q+W5aZmWld3zYBd82aNUZWtWpVI1uyZMm5CwRyYJtYldNYHDNmjJHFxMQY2cGDB43s0UcfNbLJkyf7UyIKOdsbi0+ePGlkmzdvDkI1BcP2MIbU1FQjmzdvXjDKQZDt2LHDyD777DPrsjfeeKNf23z44YeN7KGHHrIua/usJSUl+bWfguDz+UK272DgijwAAADgIBp5AAAAwEE08gAAAICDaOQBAAAABxW6ya7Nmzc3shdeeMHIcnqLq7++/vprI9u5c6eRJSQkGFmLFi383s+XX35pZLY3tNkmLeX0FtbFixf7vX8gr1q1amVk99xzj5HlNNnKNka///57I+vSpYuRrV271p8SAUnSgQMHjCwlJSX4hQTIHXfcYWT5fVMz3Pbss89a82bNmhlZYmKiX9vMqY/yd2KrbX3bxNSc9lPYJ7H6iyvyAAAAgINo5AEAAAAH0cgDAAAADqKRBwAAABxEIw8AAAA4yNmn1pQoUcKaDx8+3MjOP/98I8vMzDSyN99807rNESNGGNn27duNLC0tzchee+01I8vpqTW//PKLkfXo0cPItm7dal0fCBXbkw8++OADI4uLi/N7m7anhtieULNlyxa/twk0atTIyGyvlHdFrVq1jOzWW281sjZt2gSjHISpVatWWfOLL77YyMaMGWNkt99+u9/7+uyzz4zsm2++8Xv9s61cudKaT5w40chKlSqV5/24iivyAAAAgINo5AEAAAAH0cgDAAAADqKRBwAAABzk7GTXCRMmWPM///nPfq1vm8A6ePDgfNVUrVo1I+vdu7ff60+fPt3ImNiKcBMbG2tk3bt3NzLbxFbbxNQhQ4ZY9zNjxgwjy8jI8KNCIGdVqlQxspwm04WbIkXMa2+jRo0ysk8//dTI1q1bVyA1wW0HDhwwsl69ehlZ3759jezBBx+0bjM5OdnIVqxYkfvizqFr165GZnsggs2VV15pZP/+97/zXVMocEUeAAAAcBCNPAAAAOAgGnkAAADAQTTyAAAAgIOcmOz6t7/9zcj8ndAgST/88IORjRw5Ml812XTs2DFf69vehAmEStGiRa35Sy+9ZGS2yVE+n8/Ixo4da2S2Sd5AQTly5IiR5eaNw6FUtWpVI2vevLmR2SbyAf6yvfnelj333HPBKCdHw4cPN7LOnTsbme1c1qJFCyOrUKGCdT8///xzHqoLHq7IAwAAAA6ikQcAAAAcRCMPAAAAOIhGHgAAAHCQE5Ndp02bZmS2iReSlJaWZmRPPfWUkR09ejT/hZ0lNTU1X+svW7YsQJUA+Td06FBrbpvYanPXXXcZWU5vZAaCZfHixUZ2/fXXh6CS3LO97dj2ds2NGzcGoxwgpFJSUozM1hva3oh88cUXG9maNWus+7nhhhuMbPny5ecuMEi4Ig8AAAA4iEYeAAAAcBCNPAAAAOAgGnkAAADAQU5Mdm3durWRvfnmm9Zl33jjDSP797//HfCabN555x0j279/v5HZ3jwm5TyBFwiFb775xprv3LnTyL799lsjmzRpUsBrAiLB22+/bc1jY2ONzPYwCAC5V758eWs+e/ZsI2vcuLGR7dq1K9Al+YUr8gAAAICDaOQBAAAAB9HIAwAAAA6ikQcAAAAcRCMPAAAAOMiJp9bYXqldsWLFEFTy+3w+n5EtXLjQrwwIN7NmzbLmqampRrZjxw4jO3XqVMBrAvIrPT3dyJo0aRKCSjzXX3+9kdleHy9Jbdu2LehyAJzF9jQb2xOkQoUr8gAAAICDaOQBAAAAB9HIAwAAAA6ikQcAAAAc5MRkVwDh44svvgh1CUCezZs3z8imT59uZJ07dzay999/P1/77tSpk5FNnDjRr+Ukaffu3fnaP1DY/d///Z+Rvf766/na5o8//mhkhw4dytc2A4kr8gAAAICDaOQBAAAAB9HIAwAAAA6ikQcAAAAcxGRXAEBE69+/v5E98sgjRnbs2DHr+nFxcUZ27733GpntjeS9evUysqVLl1r3A+D3vfHGG0b2ySefGNlHH31kZN9++611m4MGDTKyvXv35qG6gsEVeQAAAMBBNPIAAACAg2jkAQAAAAfRyAMAAAAOYrIrACCivfXWW0aWmJhoZC+99JJ1fdtk1xdeeMHIxo0bZ2RHjx71p0QAfvD5fEb2008/GdnFF18cjHKCgivyAAAAgINo5AEAAAAH0cgDAAAADqKRBwAAABxEIw8AAAA4KMpnm+J7lkOHDqlMmTLBqAcR4ODBgypdunSoy8gzxgMCyfXxIDEmEDiMByCLP+OBK/IAAACAg2jkAQAAAAfRyAMAAAAOopEHAAAAHEQjDwAAADiIRh4AAABwEI08AAAA4CAaeQAAAMBBfjXyfrwzCvCb658n1+tHeCkMn6fCcAwID4Xhs1QYjgHhwZ/Pkl+N/OHDh/NdDPAb1z9PrteP8FIYPk+F4RgQHgrDZ6kwHAPCgz+fpSifH+1+Zmamdu3apfj4eEVFRQWkOEQen8+nw4cPq2LFiipSxN27uhgPCITCMh4kxgTyj/EAZMnNePCrkQcAAAAQXtz+Zy8AAAAQoWjkAQAAAAfRyAMAAAAOopEHAAAAHFQs1AUE1blmj99+uzRlSlBK+V0nTkhNmkhr1kirV0uNGoW6IhRCUU/9/ni4veHtmnLDlOAUc5bkrclqNbWV9c9W9l6pP1X6U5ArQkQI93PEgQNSv37SnDnezx07Si+/LCUkhK4mFFrhfI6QpG92f6MBCwfoq51fqWiRoupSt4vGtBujuOJxIaspFCLrqTWpqVm/nzFDevJJaePGrCw2VipTJuvnjAwpOjp49f2mf3/phx+kefNo5FFgUo9kjYcZa2foyeQntfHerPEQWyxWZUpkjYeMUxmKLhqc8ZB+Kl37j+/Plj2x6Akt/HGhtvTbwiPdUDDC/RxxzTXSjh3S6697P/ftK1WrJn34YfBqQMQI53PErsO7VP/V+rr54pt1/xX369CJQ7p/wf1KikvSrJtmBaWGcBFZt9YkJmb9KlPGu/ry289pad5VjZkzpZYtpRIlpOnTpSFDzEZ67FjvL88zTZ4s1a3rrVenjvTqq3mrcd486eOPpVGj8rY+4KfEuMTTv8qUKKMoRZ3+Oe1kmhKeS9DMdTPVckpLlRhWQtP/O11Dkoeo0WuNsm1n7PKxqja2WrZs8urJqvtKXZUYVkJ1/llHr36Vu/FQvGjxbPWVjS2rOd/P0Z2N7qSJR8EJ53PEhg3S/PnSxIlS06berwkTpLlzs/9jAwiQcD5HzP1+rqKLRuuVDq+o9gW19adKf9Ir176idze8q037N+XzyN0SWY28PwYM8L663LBBatfOv3UmTJAGDpSGD/fWGzFCeuIJaerUrGVatpR69vz97fz8s9SnjzRtmlSyZF6PAAiYAQsHqF+Tftpwzwa1q+XfeJjw9QQNXDRQw1sP14Z7NmhEmxF6YvETmpqSNR5aTmmpnrN7+l3HnI1z9MuxX9Szkf/rAAUiVOeIZcu8f1w0aZKVXXGFly1dmpcjAfItVOeIEydPqHjR4ioSldXGxhaLlSR9se2LvB2MoyLrHnl/3H+/dOONuVtn6FBp9Ois9apXl9avl8aP9+6plKSqVaWkpJy34fN5f4nfdZd02WXS1q15KB4IrPub3K8b6+ZuPAz9fKhGtx19er3q51XX+r3rNf7r8bq9kTceqpapqqS43xkPZ3lj9RtqV7OdqpSpkqtagIAL1TkiNVUqX97My5fPfksQEEShOke0rt5aD378oJ7/8nn1v6K/jqYf1eOLHpck7T68O49H4yYa+bNddlnult+7V9q+XerVy7ua/puTJ7PfS/mvf/3+dl5+WTp0SHrssdztHyhAl1XM3XjYe3Svth/arl5zeqnPh1nj4WTmyWz3Uv6r8znGwxl2HNqhBZsXaGbXmbmqBSgQoTpHSPbJuD7fuSfpAgUkVOeIi8tfrKk3TNWDCx7UY58+pqJFiqrf5f1UoVQFFS1SNHcH4Tga+bOVKpX95yJFvL8oz5SRkfX7zEzvvxMmZP/KU5KK5uLDtGiRtHy5FBOTPb/sMql79+xfwQJBUqp49vFQJKqIfMo+HjJOZY2HTJ83HiZcP0FNKmcfD0Wj8vaX6+TVk1U2tqw61u6Yp/WBgArVOSIx0bv98mx790oVKvi/HSCAQnmO6Nagm7o16Kafj/ysUsVLKUpRGrN8jKonVM/VdlxHI38u5cp5X1ueedUjJSXrzytUkCpVkrZs8RruvHrpJWnYsKyfd+3y7r+cMcP8yx8IkXIlyyn1SKp8Pt/pSacpP6ec/vMKcRVUKb6SthzYou6X5GM8/I/P59PklMnq0bBH0J6GAORKsM4RTZtKBw9KK1dKl1/uZStWeFmzZnnfLhBAwT5H/LZNSZq0epJKFCuhv9T8S0C26woa+XNp2dK74jFypNS1q/fUgHnzpNKls5YZMsSb/FS6tPd4sBMnpFWrvGf+Pvigt0yPHt5f5s88Y99P1arZf47733NQa9aUKlcO9FEBedKyWkvt/WivRn45Ul3rddX8TfM174d5Kh2TNR6GtByifvP6qXRMaV3zh2t04uQJrdq1SgfSDujBpt546PF+D1WKr6Rnrs5hPPzPoh8X6cdff1SvS3sV6HEBeRasc0TdulL79t7tOePHe1nfvtJ110m1axfkEQJ+C+Y54p8r/6lmVZoprnicPtn8iR7+5GE9e/WzSiiRUNCHGVZ4as251K3rPSbslVekhg29qyEPPZR9md69vUeCTZkiNWggXXWV9/vqZ3y9s22btDuyJmCg8Klbrq5e7fCqXvnqFTV8raFW7lqph5plHw+9G/fWxI4TNWXNFDUY10BXTblKU9ZMyfZ157aD27T7yLnHwxur31CzKs1Ut1zdgB8LEBDBPEe8+aa3ftu23q9LLvGecgaEiWCeI1buXKm/TPuLGoxroNe/eV3jrxuvfk36FchxhbPIeiEUAAAAUEhwRR4AAABwEI08AAAA4CAaeQAAAMBBNPIAAACAg2jkC8qQIVKjRqGuAggbQ5KHqNFrjUJdBhAeOEcAp3F+yLvIauR79vRe2BEVJUVHSzVqeI8JO3o01JVl+fVX6Z57pKQkqUQJ79FmH30U6qpQSPWc3VNRT0Up6qkoRQ+NVo0Xa+ihjx/S0fTwGBMtp7Q8Xd+Zvzq81SHUpaEwCvdzREaG9PTT3vtFSpTwHnc5f36oq0IhFe7nh4xTGXr6s6dV86WaKjGshBq+1lDzN0XeeIi8F0K1by9Nnuz9hbhkifd836NHpXHjzGUzMry/zIMlPV36y1+k8uWlWbO8F0Ft3y7FxwevBkSc9rXaa3Knyco4laEl25ao95zeOpp+VOOuM8dExqmMoL5h9b2b31P6qfTTP+87tk8NX2uov9b7a9BqQIQJ53PEoEHS9OnShAlSnTrSggVS587S0qXSpZcGrw5EjHA+PwxaNEjTv52uCddPUJ0L6mjBpgXqPKOzlt65VJcmRc54iKwr8pIUEyMlJkpVqkjdunmvzJ492/uz377qnDTJuxITE+O9dvvgQe8NeuXLe2/ma91aWrMm+3affdZ7FXd8vNSrl5SWlvvaJk2S9u/36mneXLrwQunKK72rLkABiSkao8S4RFUpU0XdGnRT9wbdNXvjbElZX3dOWj1JNV6soZhhMfL5fDqYdlB9P+yr8s+XV+lnSqv11NZak5p9TDz7xbOqMKqC4p+JV68PeintZO7HxPmx5ysxLvH0r0+2fKKS0SVp5FFwwvkcMW2a9Pjj0rXXevu/+26pXTtp9Oh8HjRgF87nh2n/nabHr3xc1/7hWtU4r4bu/tPdaleznUYvi6zxEHmN/NliY72rKr/ZtEmaOVN6910pJcXLOnSQUlO9W1y+/lpq3Fhq08ZruiVv+cGDpeHDvdduJyV5b/o7U3Ky93Xt1q051zJnjtS0qXdrTYUKUv360ogR0qlTATxg4PfFRscq41TWmNi0f5Nmrpupd296Vyl3pUiSOrzVQalHUvVR94/0dd+v1Tipsdr8q432H/fGxMx1MzU4ebCGtx6uVX1WKSk+Sa9+lX1MJG9NVtRTUdr661a/a3tj9Ru6pf4tKlW8VL6PE/BLOJ0jTpzwbqk5u74vvsjnQQL+Cafzw4lTJ1SiWPbxEBsdqy+2RdZ4iLxba860cqX01lveX7i/SU/3rnqUK+f9vGiR9O230p493tUXSRo1yrtCM2uWdxVm7Fjpzju9r2AladgwaeHC7FdcSpaUatf+/a9ht2zx9te9u3dC+OEHr6k/eVJ68slAHjlgtXLnSr317VtqUyNrTKSfSte0ztNUrpQ3Jhb9uEjf7vlWex7ao5hi3pgY1XaUZn83W7PWz1LfP/bV2OVjdWejO9W7sTcmhrUepoVbFma76lIyuqRql62t6CL+fRW7cudKrd2zVm90fCNQhwv8vnA7R7RrJ40ZI7Vo4d0n/+mn0gcfcLEHQRFu54d2NdtpzPIxanFhC9U8v6Y+3fKpPvjuA53yRdZ4iLxGfu5cKS7Oa44zMqROnaSXX8768wsvzPoLWvKurhw5IpUtm307x49Lmzd7v9+wQbrrrux/3rSptHhx1s+XXy59993v15aZ6X01+/rrUtGi0h//KO3aJT3/PI08Cszc7+cqbkScTmaeVEZmhjrV7qSXr8kaExcmXHj6L2lJ+nrX1zqSfkRlR2YfE8dPHtfm/d6Y2PDLBt11WfYx0bRyUy3emjUmLq90ub679xxj4gxvfPOG6pevr8srXZ6r4wNyJZzPES++KPXp490fHxXlNfN33OHd0w8UgHA+P7zY/kX1+bCP6rxSR1GKUs3za+qORndockpkjYfIa+RbtfImLUVHSxUrmlc/Sp31lX1mpvc1aHKyua2EhMDWlpTk1VO0aFZWt673lW16ulS8eGD3B0hqVb2VxnUYp+gi0aoYX9GYrFQqOvuYyPRlKikuSck9k41tJZRIKJAaj2Uc09vr3tbTLZ8ukO0Dp4XzOaJcOe9Kf1qatG+fV9+jj0rVqwd2P8D/hPP5oVypcpp9y2ylnUzTvmP7VDG+oh5d+KiqnxdZ4yHyGvlSpaRatfxfvnFjr5EuVkyqVs2+TN260vLlUo8eWdny5bmvrXlz72vczEypyP+mL3z/vXeSoIlHASkVXUq1zvd/TDROaqzUI6kqVqSYqiVUsy5T94K6Wr5juXo0zBoTy3fmYUz8z8x1M3Xi5An97ZK/5XkbgF/C+RzxmxIlpEqVvG8M3n1XuummvG8L+B0unB9KFCuhSqUrKeNUht7d8K5uujiyxgOTXc/l6qu9r0BvuMF71NfWrd6jvgYN8iYtSVL//t5TDCZN8hrvwYOldeuyb2flSu/r0J07c97X3Xd7V1n69/e285//eJNd77mnoI4OyLWra1ytplWa6oa3b9CCTQu09detWrp9qQYtGqRVu7wx0b9Jf01aPUmTVk/S9/u+1+DFg7VuT/YxsXLnStX5Zx3tPPQ7Y+J/3lj9hm6oc4PKlix7zmWBoArmOWLFCum997z5VEuWeI/KzMyUHnmkoI4OyJVgnh9W7Fih9za8py0HtmjJT0vU/s32yvRl6pHmkTUeIu+KfG5FRXkTTwcO9CYr7d3rPZqsRQvvyTKSdPPN3r2QAwZ4X3l26eI15QsWZG3n2DFp48bsTz84W5Uq0scfSw88IF1yiXfFpX9/b7tAmIiKitJH3T7SwEUDdeecO7X36F4lxiWqxYUtVKGUNyZurn+zNh/YrAELByjtZJq61O2iuy+7Wws2Z42JYxnHtHHfRmVk/s6YkPT9vu/1xbYv9PHfPi7Q4wLyJJjniLQ07x8IW7Z49/Ffe6038TbQt/AAeRTM80PayTQNWjRIWw5sUVzxOF37h2s1rfO0ArvFM1xF+Xw+X6iLAAAAAJA73FoDAAAAOIhGHgAAAHAQjTwAAADgIBp5AAAAwEE08gAAAICDaOQBAAAAB9HIAwAAAA6ikQcAAAAcRCMPAAAAOIhGHgAAAHAQjTwAAADgoGL+LJSZmaldu3YpPj5eUVFRBV0TCimfz6fDhw+rYsWKKlLE3X9DMh4QCIVlPEiMCeQf4wHIkpvx4Fcjv2vXLlWpUiUgxQHbt29X5cqVQ11GnjEeEEiujweJMYHAYTwAWfwZD379szc+Pj4gBQGS+58n1+tHeCkMn6fCcAwID4Xhs1QYjgHhwZ/Pkl+NPF8NIZBc/zy5Xj/CS2H4PBWGY0B4KAyfpcJwDAgP/nyW3L4RDQAAAIhQNPIAAACAg2jkAQAAAAfRyAMAAAAOopEHAAAAHEQjDwAAADiIRh4AAABwEI08AAAA4CAaeQAAAMBBNPIAAACAg2jkAQAAAAfRyAMAAAAOopEHAAAAHEQjDwAAADiIRh4AAABwEI08AAAA4CAaeQAAAMBBxUJdgAvGjRtnZH379jWye+65x8hee+21AqkJKGhxcXHW/PHHHzeyKlWqGFn37t2NbMqUKUb2wAMPWPdz8ODBc1QIAEDBOu+884wsJibGr3VTU1MDXY6BK/IAAACAg2jkAQAAAAfRyAMAAAAOopEHAAAAHMRk1zNUq1bNmnfr1s3IfD6fkdkmATLZFS6oX7++kT3zzDPWZa+99lojO3r0qJGtWbPGyG6//XYj27dvn3U/Dz/8sDUHXLBkyRIjs33WbZPCbeMJKAi2iZw33nijkV111VVGZuuDcrJhwwYjmzdvnpHt3r3byPbs2eP3fmzHU7VqVSOzHc8f//hH6zZbt25tZElJSUa2fv16I7vkkkus2wwkrsgDAAAADqKRBwAAABxEIw8AAAA4iEYeAAAAcBCTXc9ge1urJJUqVcqv9StWrBjIcoACERsba2QTJ040sj/96U/W9W1vZ7VNjLVNUHryySeNbNWqVdb9AC47ceKEkbVv397I/vCHPxhZSkpKQZQEGGxvpB8yZIiRRUVFGVluJrvaDBs2zMi++uorI+vTp491/aZNmxrZvffea2QXX3yxkeXmeN577z0jmzBhgpF99tln1vULGlfkAQAAAAfRyAMAAAAOopEHAAAAHEQjDwAAADiIya5AhPnggw+MzDaxderUqdb1e/fubWT+Tnp66KGH/FoOcJ1tAnlcXJyRlSxZMhjlAFZdunTxa7m0tDQje+edd6zLbt261chmzZrl13769etnZMnJydZlExISjGzLli1Gdv/99xvZ559/bmSZmZnW/fz0009GdvjwYeuyocAVeQAAAMBBNPIAAACAg2jkAQAAAAfRyAMAAAAOopEHAAAAHMRTa86wceNGa37y5EkjK1aM/3UIf7feequRtWzZ0shefvllIxs6dKh1m/l9LffZqlWrZs0TExONrH79+kYWGxtrZLbXfK9du9a6nyNHjpyjQiD37rnnHiNr0qSJkXXv3t3Ili5dWiA1AXll64NGjhxpXXb9+vV53s+cOXOM7MCBA9ZlbU/HefPNN43s0KFDea7HBVyRBwAAABxEIw8AAAA4iEYeAAAAcBCNPAAAAOAgZmyeIadX0r/wwgtGVrp06YIuB/DbZZddZs1ff/11I7NNWnr77beNbN++ffkvzA+212dL0n333RfQ/eQ0AWvMmDFGZnt99+bNmwNaDwq3hQsXGlnz5s1DUAmQsxEjRhjZxIkTjczW8zz88MPWbd51111GduLECb/qmTt3rl8ZsnBFHgAAAHAQjTwAAADgIBp5AAAAwEE08gAAAICDmOwKFAJXX321NS9ZsqSR3XDDDUa2fPnyQJfkt0GDBllz2yQsf9neCpvTfiZMmGBkP/30k5G1a9fOyDZt2pSH6hAJ8vN2SyBY3nnnHSOznTcmTZpkZLfddpt1mxkZGUbWv39/Izt+/Lg/JeIcuCIPAAAAOIhGHgAAAHAQjTwAAADgIBp5AAAAwEFRPp/Pd66FDh06pDJlygSjnrC0f/9+I/P3za4vvviikf3jH//Id00uO3jwoNNvxg31eChevLiRzZ8/37rsVVddZWTx8fFGduzYsfwX5ijbGL333nuNLDk52ciuueYa6zbT09P93r/r40EK/Zhwhe1z8emnnxpZTp+rSMB4CE/PPfeckeWml1m2bJmRdezY0cgOHDiQu8IKOX/GA1fkAQAAAAfRyAMAAAAOopEHAAAAHEQjDwAAADiIRh4AAABwULFQF+CCMWPGGNmQIUP8WveWW24xsldeecW67JYtW3JVFyJT5cqVjcz2dBr458EHHzSyGjVqGNm1115rZH/+85+t27Q9iQRYsWKFkVWqVCkElQC5M2jQICOzPdFPsj/1q2nTpkY2evRov7J169b5U2LE4oo8AAAA4CAaeQAAAMBBNPIAAACAg2jkAQAAAAcx2dUPmzdvzvO6iYmJRlayZMn8lIMI17NnT7+XnTFjhpGlpaUFsBr3nTp1yshSU1P9Wve6666z5kx2hc23335rZH369DGyWrVqWdfftGlTwGsC/JGRkWFkzz33nHXZjRs3GtmsWbOMrEePHkZ2wQUXGNmjjz5q3c/69euteaThijwAAADgIBp5AAAAwEE08gAAAICDaOQBAAAABzHZ1Q8//PCDkf38889GZpvYWqQI/1ZCYJUuXdrIcvqcjRgxwsgyMzMDXlMkiIqKCnUJKISKFi1qZM2bN7cuy2RXuGD27NlG1rBhQyNbuHChkV1//fVGVr16det+WrRoYWQHDhzwo8LChS4TAAAAcBCNPAAAAOAgGnkAAADAQTTyAAAAgIOY7OqHVatWGZlt0lGFChWMzDaxsGbNmtb9rF27Ng/VAdJPP/1kzfft2xfkSgovn89nZNu2bQtBJQDglnXr1hlZmzZtjMz2tthrrrnGus3//ve/RtasWTMj2759uz8lOosr8gAAAICDaOQBAAAAB9HIAwAAAA6ikQcAAAAcxGTXEHjggQes+QcffBDkSlBYVKlSxZqXLVvWyHbv3l3Q5TglOjrayC666CIjs01snTZtWoHUhMjBG4MRaPXr1zey++67z7rs5s2bjWzkyJEBr8lm/fr1RvbEE08YWaNGjazrJyUlGdlbb71lZLZjT0lJOXeBjuCKPAAAAOAgGnkAAADAQTTyAAAAgINo5AEAAAAH0cgDAAAADuKpNQAi2rXXXmtkTZs2NbIBAwYY2S+//FIgNSFy+Hy+UJcAh7Vo0cLI3nvvPSNLSEiwrj9w4MBAl5QvtqfJ9OzZ07rsggULjMz2d/ett97q135cxRV5AAAAwEE08gAAAICDaOQBAAAAB9HIAwAAAA5ismse2V4jvGjRohBUAuQsMTHRyNauXRuCSkLP9tpySZo4caKRPf7440b2wgsvBLwm4NSpU0b22WefhaASuOg///mPkcXGxhrZqFGjrOuPHj064DUF2ueff27NbbX/4x//MLK7777byN555x0jW7VqVR6qCz2uyAMAAAAOopEHAAAAHEQjDwAAADiIRh4AAABwEJNd82j//v15XrdevXrWvHPnzkb2/vvv53k/KJw2btzo97KPPvqokSUnJxvZyZMn81NS2OnSpYuRTZ482brs0KFDjSyniWFAoGVmZhrZ1q1bg18InGSbCNq+fXsje/jhh63rd+jQwcjmzZtnZGPGjDGygwcPWrd5/Phxa55XGRkZ1tz2tu127doZWYMGDYzsww8/NLKkpKQ8VBd6XJEHAAAAHEQjDwAAADiIRh4AAABwEI08AAAA4CAmu4bA+eefb81tb5hksivONmPGDCP7v//7P+uyrVq1MrLWrVsbme2txOE4ATY6OtrIBg4caGSPPPKIkX333XfWbb766qv5LwwAQqBr165GdtdddxnZgw8+aF2/WrVqfi1re2Pql19+ad2m7a2ppUqVMjLbpFqbnCbP2s5RMTExRubz+fzKXMUVeQAAAMBBNPIAAACAg2jkAQAAAAfRyAMAAAAOivL5ccf/oUOHVKZMmWDU44z69esbWUpKipFFRUUZWU7/y21vSStbtmzuiwtzBw8eVOnSpUNdRp6F43ho0qSJNV+8eLGR2SYDvf3220ZmeyusJG3fvj2X1f2+4sWLW/OLLrrIyGxvYe3YsaORffXVV34tJ0l79uw5V4kFyvXxIIXnmAhHhw8fNjLb5982RiMF46Fg2Ca1SlJiYqKR2R6S0KdPHyOrWrVqvus6m61nso0bSUpPTzeynB4mcjbbQw769evn17rB5M944Io8AAAA4CAaeQAAAMBBNPIAAACAg2jkAQAAAAfRyAMAAAAOKhbqApBlzJgxoS4BjlqxYoU1tz19YOLEiUZ2yy23GFnr1q2t21y3bl0uq/t9sbGx1vyKK67wa/1BgwYZ2aRJk4ws1E+nAWxPo5k7d24IKkGk2bp1q9/58uXLjWzKlClGVq9ePes2b7vtNr9q6tKli5GVLFnSyOLi4vzaXk5sT2CbOnVqvrYZTrgiDwAAADiIRh4AAABwEI08AAAA4CAaeQAAAMBBTHbNo927dxvZkiVLjKxFixZ+b3Pz5s35qgk4m20SrO0zaZvIdN1111m3Wb58+XzXdaacXr/90ksvGdmbb75pZN98842RZWZm5r8wIAhs5xIg3Ng+pzl9dj/99FO/tvnwww8bWZEi5vVln8/n1/Zy8ssvvxhZYTpHcEUeAAAAcBCNPAAAAOAgGnkAAADAQTTyAAAAgIOY7JpH+/btMzLbWzSBcHPgwAEj69SpUwgqAQBEqr1794a6hEKBK/IAAACAg2jkAQAAAAfRyAMAAAAOopEHAAAAHMRkVwAAgqB48eKhLgFAIcMVeQAAAMBBNPIAAACAg2jkAQAAAAfRyAMAAAAOopEHAAAAHEQjDwAAADiIRh4AAABwEI08AAAA4CAaeQAAAMBBNPIAAACAg2jkAQAAAAfRyAMAAAAOopEHAAAAHEQjDwAAADjIr0be5/MVdB2IIK5/nlyvH+GlMHyeCsMxIDwUhs9SYTgGhAd/Pkt+NfKHDx/OdzHAb1z/PLleP8JLYfg8FYZjQHgoDJ+lwnAMCA/+fJaifH60+5mZmdq1a5fi4+MVFRUVkOIQeXw+nw4fPqyKFSuqSBF37+piPCAQCst4kBgTyD/GA5AlN+PBr0YeAAAAQHhx+5+9AAAAQISikQcAAAAcRCMPAAAAOIhGHgAAAHBQsVAXEExRT/3+7PHbG96uKTdMCU4xFsM/H67//PAfpaSmqHjR4vr10V9DVgsKv3AfDweOH1C/+f00Z+McSVLH2h318jUvK6FEQshqQuEW7mOCcwSC6lxP3Ln9dmnKlKCUYlWtmvTTT9mzAQOkZ58NSTmhElGN/O5/7D79+xlrZ+jJ5Ce18d6Np7PYYrHZls84laHootFBqy/9VLr+Wu+valq5qd5Y/UbQ9ovIFO7jodt73bTj0A7N7z5fktR3bl/d9v5t+vDWD4NWAyJLuI8JzhEIqt1Z40EzZkhPPiltzBoPis0+HpSRIUUHbzxIkp5+WurTJ+vnuLjg7j8MRNStNYlxiad/lSlRRlGKOv1z2sk0JTyXoJnrZqrllJYqMayEpv93uoYkD1Gj1xpl287Y5WNVbWy1bNnk1ZNV95W6KjGshOr8s45e/erVXNf3VKun9EDTB9SgQoN8HCXgn3AeDxv2btD8TfM18fqJalqlqZpWaaoJ10/Q3O/nauMvG8+9ASAPwnlMSJwjEGSJiVm/ypTxrtD/9nNampSQIM2cKbVsKZUoIU2fLg0ZIjVqlH07Y8d6V8/PNHmyVLeut16dOtKruR8PkqT4+Ox10shjwMIB6teknzbcs0HtarXza50JX0/QwEUDNbz1cG24Z4NGtBmhJxY/oakpU08v03JKS/Wc3bOAqgYKRqjGw7Idy1QmpoyaVG5yOrui8hUqE1NGS7cvzfPxAPnFOQI4w4ABUr9+0oYNUjv/xoMmTJAGDpSGD/fWGzFCeuIJaWrWeFDLllLPnufe1nPPSWXLev94GD5cSk/Pw0G4LaJurfHH/U3u1411b8zVOkM/H6rRbUefXq/6edW1fu96jf96vG5vdLskqWqZqkqKSwp4vUBBCtV4SD2SqvKlyht5+VLllXokNVf1AIHEOQI4w/33Szfmbjxo6FBp9Ois9apXl9avl8aP9+67l6SqVaWkc4yH/v2lxo2l886TVq6UHntM+vFHaeLEXB+Gy2jkz3JZxctytfzeo3u1/dB29ZrTS30+zLpP62TmSZUpUeb0z//q/K+A1QgESyjHg+3V5j75eOU5QopzBHCGy3I3HrR3r7R9u9SrV/Z720+e9G7f+c2//BgPDzyQ9ftLLvEa+q5ds67SRwga+bOUKl4q289FoorIJ1+2LONUxunfZ/oyJUkTrp+Q7TYASSoaVbSAqgSCI1TjITEuUT8f+dnI9x7dqwqlKvi9HSDQOEcAZyiVfTyoSBHJl308KCNrPCjTGw+aMEFqkn08qGg+x8MVV3j/3bSJRh5ZypUsp9QjqfL5sq4EpvyccvrPK8RVUKX4StpyYIu6X9I9RFUCwRGs8dC0clMdPHFQK3eu1OWVLpckrdixQgdPHFSzKs3ydQxAIHGOAM5QrpyUmuo18799e5qSkvXnFSpIlSpJW7ZI3QM8Hlav9v57rltyChka+XNoWa2l9n60VyO/HKmu9bpq/qb5mvfDPJWOKX16mSEth6jfvH4qHVNa1/zhGp04eUKrdq3SgbQDerDpg5KkHu/3UKX4Snrm6mdy3Ne2g9u0//h+bTu4Tad8p5SSmiJJqnV+LcUVj7yZ2Ag/wRoPdcvVVfta7dXnwz4af914SVLfD/vquouuU+0Lahf8gQJ+4hwBnKFlS+/2mZEjvdtc5s+X5s2TSmeNBw0Z4k2QLV1auuYa6cQJadUq6cAB6UFvPKhHD6/hfyaH8bBsmbR8udSqlXdLzldfebfadOzo3V8fQXhqzTnULVdXr3Z4Va989YoavtZQK3et1EPNHsq2TO/GvTWx40RNWTNFDcY10FVTrtKUNVNUPaH66WW2Hdym3Ud2n735bJ5c/KQuHX+pBicP1pH0I7p0/KW6dPylWrVrVYEcG5BbwRwPb974phqUb6C209qq7bS2uqTCJZrWeVqBHBeQV5wjgDPUres9SvKVV6SGDb1JqA9lHw/q3dubkDplitSggXTVVd7vq2eNB23blv059meLifGebd+ypVSvnveM+z59pH//uwAOKrxF+Xxn38wEAAAAINxxRR4AAABwEI08AAAA4CAaeQAAAMBBNPIAAACAg2jkAQAAAAfRyBeQIclD1Oi1RqEuAwgbjAkgC+MBOMOQIVKjRqGuwkkR1cj3nN1TUU9FKeqpKEUPjVaNF2vooY8f0tH0o6EuTZK0bs86dZnZRdXGVlPUU1Eau3xsqEtCIRfuY0KS3l3/ruq9Uk8xw2JU75V6en/D+6EuCYVUuI8HzhEIqp49vbezRkVJ0dFSjRreM+GPhsd4kCSNHSvVri3FxkpVqngvhUpLC3VVQRVxb3ZtX6u9JnearIxTGVqybYl6z+mto+lHNe66ccayGacyFF00Omi1Hcs4phoJNfTXen/VAwseCNp+EdnCeUws275MN8+6WUNbDVXnup31/ob3ddOsm/TFHV+oSeUmQasDkSOcxwPnCARd+/bS5MlSRoa0ZIn3MqejR6Vx5nhQRobX8AfLm29Kjz4qTZokNWsmff+9948PSXrhheDVEWIRdUVekmKKxigxLlFVylRRtwbd1L1Bd83eOFtS1ledk1ZPUo0XayhmWIx8Pp8Oph1U3w/7qvzz5VX6mdJqPbW11qSuybbdZ794VhVGVVD8M/Hq9UEvpZ3M/b8I/1TpT3q+7fO6pf4tiikaE4jDBc4pnMfE2BVj9Zeaf9Fjf35MdS6oo8f+/JjaVG+jsSvGBuDIAVM4jwfOEQi6mBgpMdG72t2tm9S9uzR7tvdnv90OM2mSd7U+Jkby+aSDB6W+faXy5aXSpaXWraU12ceDnn1WqlBBio+XevXK21X0Zcuk5s29uqpVk9q2lW69VVoVWW86jrhG/myx0bHKOJVx+udN+zdp5rqZevemd5VyV4okqcNbHZR6JFUfdf9IX/f9Wo2TGqvNv9po//H9kqSZ62ZqcPJgDW89XKv6rFJSfJJe/erVbPtJ3pqsqKeitPXXrcE6NCBPwmlMLNu+TG1rtM2WtavZTku3Lw3MwQLnEE7jAQi52FjvyvtvNm2SZs6U3n1XSknxsg4dpNRU6aOPpK+/lho3ltq0kfZ740EzZ0qDB0vDh3tNd1KS9Gr28aDkZO+Wnq1bc67lyiu97a9c6f28ZYu3zw4dAnSwboi4W2vOtHLnSr317VtqU6PN6Sz9VLqmdZ6mcqXKSZIW/bhI3+75Vnse2qOYYt4VkFFtR2n2d7M1a/0s9f1jX41dPlZ3NrpTvRv3liQNaz1MC7cszHbFpWR0SdUuW1vRRYL4tROQS+E2JlKPpKpCXIVsWYW4Cko9khqwYwZyEm7jAQiplSult97ymvLfpKdL06ZJ5bzxoEWLpG+/lfbs8a7QS9KoUd5V/FmzvCv1Y8dKd97p3aYjScOGSQsXZr8qX7Kkd+/7792qc8st0t69XkPv80knT0p33+3dbhNBIq6Rn/v9XMWNiNPJzJPKyMxQp9qd9PI1L5/+8wsTLjz9F7Qkfb3rax1JP6KyI8tm287xk8e1ef9mSdKGXzborsvuyvbnTSs31eKti0//fHmly/Xdvd8VxCEB+RLuYyJKUdl+9vl8RgYESriPByCo5s6V4uK8JjkjQ+rUSXo5azzowguzmnjJu0J+5IhUNvt40PHj0mZvPGjDBumu7ONBTZtKi7PGgy6/XPruHOMhOdm7qv/qq1KTJt63A/37e1f4n3gi14fqqohr5FtVb6VxHcYpuki0KsZXNCYqlYoule3nTF+mkuKSlNwz2dhWQomEAqwUCI5wHhOJcYnG1fc9R/cYV+mBQAnn8QAEXatW3sTW6GipYkXzCnmp7ONBmZleI52cbG4rISGwtT3xhHTbbVlX9hs08Cbi9u0rDRwoFYmMu8cjrpEvFV1Ktc6v5ffyjZMaK/VIqooVKaZqCdWsy9S9oK6W71iuHg17nM6W71ye31KBoAjnMdG0SlN9suUTPdA06wkdH2/5WM2qNMv1tgB/hPN4AIKuVCmplv/jQY0be/fHFyvmTUC1qVtXWr5c6pE1HrQ8D+Ph2DGzWS9a1LvNxufL/fYcFRn/XMmHq2tcraZVmuqGt2/Qgk0LtPXXrVq6fakGLRqkVbu8mdH9m/TXpNWTNGn1JH2/73sNXjxY6/asy7adlTtXqs4/62jnoZ057iv9VLpSUlOUkpqi9FPp2nlop1JSU7Rp/6YCPUYgN4I5Jvo36a+PN3+s5754Tt/98p2e++I5LdyyUPc3ub8gDxHwG+cI4AxXX+3dJnPDDdKCBd5k1aVLpUGDsp4m07+/96SbSZO8R0YOHiytyz4etHKlVKeOtDPn8aDrr/e+LXj7benHH6VPPvGu0nfs6DX0ESLirsjnVlRUlD7q9pEGLhqoO+fcqb1H9yoxLlEtLmyhCqW8r/dvrn+zNh/YrAELByjtZJq61O2iuy+7Wws2Lzi9nWMZx7Rx30ZlZGbktCvtOrxLl46/9PTPo5aN0qhlo3TVhVdZv7YFQiGYY6JZlWZ6u+vbGrRokJ5Y/IRqnl9TM7rO4BnyCBucI4AzREV5T44ZONCb0Lp3r/f4yhYtvMdNStLNN3v3yw8Y4E1w7dLFm6S6IGs86NgxaePG7E/IOdugQd7+Bg3yGv5y5bzmfvjwgj3GMBPl80XQ9w8AAABAIcGtNQAAAICDaOQBAAAAB9HIAwAAAA6ikQcAAAAcRCMPAAAAOIhGHgAAAHAQjTwAAADgIBp5AAAAwEE08gAAAICDaOQBAAAAB9HIAwAAAA76f9x7wtF2I955AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x400 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_data(X_test.reshape(X_test.shape[0], 28, 28), y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "digit-recognition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
